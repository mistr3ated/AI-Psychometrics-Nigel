{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9909b618-7c07-4047-91b8-52e407eb6cdc",
   "metadata": {},
   "source": [
    "## We're going to deconstruct the components of the GPT2 decoder model and manually reconstruct its output externally in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681d4d59-65e2-4ce9-a7b5-b06b04c298ab",
   "metadata": {},
   "source": [
    "## Step 1: Use GPT2 to tokenize our input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebe42a22-db1f-4465-8cfa-2ce94e014343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token           | Offsets     | Text Segment\n",
      "---------------------------------------------\n",
      "Open            | ( 0,  4)   | 'Open'\n",
      "-               | ( 4,  5)   | '-'\n",
      "source          | ( 5, 11)   | 'source'\n",
      "Ä LL             | (11, 14)   | ' LL'\n",
      "Ms              | (14, 16)   | 'Ms'\n",
      "Ä rock           | (16, 21)   | ' rock'\n",
      ".               | (21, 22)   | '.'\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "import torch\n",
    "\n",
    "# Load GPT-2 tokenizer (fast version only)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Input sentence\n",
    "sentence = \"Open-source LLMs rock.\"\n",
    "\n",
    "# Tokenize with offset mapping (GPT-2 doesn't use special tokens like [CLS])\n",
    "encoding = tokenizer(sentence, return_tensors=\"pt\", return_offsets_mapping=True, add_special_tokens=False)\n",
    "\n",
    "# Extract input IDs and offset mappings\n",
    "input_ids = encoding[\"input_ids\"]\n",
    "offsets = encoding[\"offset_mapping\"][0]  # shape: (seq_len, 2)\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "# Print token â†’ offset â†’ original string span\n",
    "print(f\"{'Token':15} | {'Offsets':11} | Text Segment\")\n",
    "print(\"-\" * 45)\n",
    "for token, (start, end) in zip(tokens, offsets):\n",
    "    span = sentence[start:end]\n",
    "    print(f\"{token:15} | ({start:2}, {end:2})   | '{span}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba8b3c-f6c6-4637-bab6-ba7ff75e5fd2",
   "metadata": {},
   "source": [
    "## Step 1a: We replicate using an alternate tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b15a44f5-5367-4068-9d09-9046c49aabd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token           | Token ID | Offsets     | Text Segment\n",
      "-------------------------------------------------------\n",
      "Open            |     11505 | ( 0,  4)   | 'Open'\n",
      "-               |        12 | ( 4,  5)   | '-'\n",
      "source          |     10459 | ( 5, 11)   | 'source'\n",
      "Ä LL             |     27140 | (11, 14)   | ' LL'\n",
      "Ms              |     10128 | (14, 16)   | 'Ms'\n",
      "Ä rock           |      3881 | (16, 21)   | ' rock'\n",
      ".               |        13 | (21, 22)   | '.'\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "# Load the raw tokenizer from Hugging Face's pretrained assets\n",
    "tokenizer_indep = Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Your sentence\n",
    "sentence = \"Open-source LLMs rock.\"\n",
    "\n",
    "# Encode using the low-level tokenizer\n",
    "output = tokenizer_indep.encode(sentence)\n",
    "\n",
    "# Extract tokens, IDs, and offsets\n",
    "tokens_indep = output.tokens\n",
    "ids_indep = output.ids\n",
    "offsets_indep = output.offsets\n",
    "\n",
    "# Print the results\n",
    "print(f\"{'Token':15} | {'Token ID':8} | {'Offsets':11} | Text Segment\")\n",
    "print(\"-\" * 55)\n",
    "for token, id_, (start, end) in zip(tokens_indep, ids_indep, offsets_indep):\n",
    "    print(f\"{token:15} | {id_:9} | ({start:2}, {end:2})   | '{sentence[start:end]}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae1002-a81d-4e2e-9bc2-17109490b97b",
   "metadata": {},
   "source": [
    "## Step 2: Grab the internal pre-trained raw token embeddings for these tokens from GPT-2.\n",
    "There is no external parallel to this step, these embeddings are pretrained, we take them and use them in our computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4c8daf0-33fa-4351-ab21-dd86b1e18eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_0</th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>0.112828</td>\n",
       "      <td>-0.125863</td>\n",
       "      <td>0.107890</td>\n",
       "      <td>-0.186214</td>\n",
       "      <td>0.141399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>0.061386</td>\n",
       "      <td>-0.014965</td>\n",
       "      <td>0.056575</td>\n",
       "      <td>-0.089331</td>\n",
       "      <td>0.017219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>-0.077845</td>\n",
       "      <td>-0.248645</td>\n",
       "      <td>-0.003302</td>\n",
       "      <td>-0.089265</td>\n",
       "      <td>0.033541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ä LL</th>\n",
       "      <td>0.074989</td>\n",
       "      <td>-0.192921</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.238938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>0.043708</td>\n",
       "      <td>-0.197578</td>\n",
       "      <td>0.300682</td>\n",
       "      <td>-0.120869</td>\n",
       "      <td>-0.081312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ä rock</th>\n",
       "      <td>-0.097493</td>\n",
       "      <td>-0.034077</td>\n",
       "      <td>0.096704</td>\n",
       "      <td>-0.002258</td>\n",
       "      <td>0.035320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.046641</td>\n",
       "      <td>-0.011302</td>\n",
       "      <td>0.028328</td>\n",
       "      <td>0.046351</td>\n",
       "      <td>0.039038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dim_0     dim_1     dim_2     dim_3     dim_4\n",
       "Open    0.112828 -0.125863  0.107890 -0.186214  0.141399\n",
       "-       0.061386 -0.014965  0.056575 -0.089331  0.017219\n",
       "source -0.077845 -0.248645 -0.003302 -0.089265  0.033541\n",
       "Ä LL     0.074989 -0.192921 -0.000050  0.007463  0.238938\n",
       "Ms      0.043708 -0.197578  0.300682 -0.120869 -0.081312\n",
       "Ä rock  -0.097493 -0.034077  0.096704 -0.002258  0.035320\n",
       ".       0.046641 -0.011302  0.028328  0.046351  0.039038"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved to gpt2_token_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Model\n",
    "import pandas as pd\n",
    "\n",
    "# Load model\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Get token embeddings\n",
    "with torch.no_grad():\n",
    "    embeddings = model.wte(input_ids).squeeze(0)\n",
    "\n",
    "# Convert to numpy\n",
    "emb_matrix = embeddings.cpu().numpy()\n",
    "\n",
    "# Convert token IDs to tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(emb_matrix, index=tokens)\n",
    "df.columns = [f\"dim_{i}\" for i in range(df.shape[1])]\n",
    "\n",
    "# Show first 5 dimensions\n",
    "display(df[[f\"dim_{i}\" for i in range(5)]])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"gpt2_token_embeddings.csv\", index_label=\"token\")\n",
    "print(\"âœ… Saved to gpt2_token_embeddings.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36d772-c70e-47e4-bdac-6b7412b7c5b1",
   "metadata": {},
   "source": [
    "## Step 3: Get learned positional encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9abd7c26-4e4e-460f-83b9-696f51f86da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_0</th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pos_0</th>\n",
       "      <td>-0.018821</td>\n",
       "      <td>-0.197419</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.011347</td>\n",
       "      <td>0.063824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_1</th>\n",
       "      <td>0.023959</td>\n",
       "      <td>-0.053792</td>\n",
       "      <td>-0.094879</td>\n",
       "      <td>-0.012909</td>\n",
       "      <td>-0.010051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_2</th>\n",
       "      <td>0.004216</td>\n",
       "      <td>-0.084764</td>\n",
       "      <td>0.054515</td>\n",
       "      <td>-0.004668</td>\n",
       "      <td>-0.026065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_3</th>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.073803</td>\n",
       "      <td>0.105526</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>-0.015574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_4</th>\n",
       "      <td>0.007637</td>\n",
       "      <td>-0.025090</td>\n",
       "      <td>0.126956</td>\n",
       "      <td>-0.006254</td>\n",
       "      <td>-0.012381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_5</th>\n",
       "      <td>0.009602</td>\n",
       "      <td>-0.033885</td>\n",
       "      <td>0.131233</td>\n",
       "      <td>-0.003855</td>\n",
       "      <td>-0.010249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_6</th>\n",
       "      <td>0.002679</td>\n",
       "      <td>-0.020530</td>\n",
       "      <td>0.119613</td>\n",
       "      <td>-0.002906</td>\n",
       "      <td>-0.008992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dim_0     dim_1     dim_2     dim_3     dim_4\n",
       "pos_0 -0.018821 -0.197419  0.004027  0.011347  0.063824\n",
       "pos_1  0.023959 -0.053792 -0.094879 -0.012909 -0.010051\n",
       "pos_2  0.004216 -0.084764  0.054515 -0.004668 -0.026065\n",
       "pos_3 -0.000283 -0.073803  0.105526  0.000652 -0.015574\n",
       "pos_4  0.007637 -0.025090  0.126956 -0.006254 -0.012381\n",
       "pos_5  0.009602 -0.033885  0.131233 -0.003855 -0.010249\n",
       "pos_6  0.002679 -0.020530  0.119613 -0.002906 -0.008992"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved to gpt2_position_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "# Get position IDs (same length as input)\n",
    "position_ids = torch.arange(input_ids.size(1), dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "# Get positional embeddings from GPT-2\n",
    "with torch.no_grad():\n",
    "    pos_embeddings = model.wpe(position_ids).squeeze(0)\n",
    "\n",
    "# Convert to DataFrame\n",
    "pos_matrix = pos_embeddings.cpu().numpy()\n",
    "df_pos = pd.DataFrame(pos_matrix, index=[f\"pos_{i}\" for i in range(pos_matrix.shape[0])])\n",
    "df_pos.columns = [f\"dim_{i}\" for i in range(pos_matrix.shape[1])]\n",
    "\n",
    "# Show first few dimensions\n",
    "display(df_pos[[f\"dim_{i}\" for i in range(5)]])\n",
    "\n",
    "# Save to CSV\n",
    "df_pos.to_csv(\"gpt2_position_embeddings.csv\", index_label=\"position\")\n",
    "print(\"âœ… Saved to gpt2_position_embeddings.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f42edc6-a73e-4a17-9485-ac1268217d1e",
   "metadata": {},
   "source": [
    "## Step 4: Get input tensor to first transformer block\n",
    "Tensor shape will be seq_len, 768 --> 7,768 or a 1, 7, 768 tensor which is squeezed to flatten batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a1c876-8aae-47c2-8fc3-5c944453ac27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_0</th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>0.094007</td>\n",
       "      <td>-0.323282</td>\n",
       "      <td>0.111917</td>\n",
       "      <td>-0.174867</td>\n",
       "      <td>0.205223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>0.085346</td>\n",
       "      <td>-0.068757</td>\n",
       "      <td>-0.038304</td>\n",
       "      <td>-0.102240</td>\n",
       "      <td>0.007169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>-0.073628</td>\n",
       "      <td>-0.333408</td>\n",
       "      <td>0.051213</td>\n",
       "      <td>-0.093934</td>\n",
       "      <td>0.007476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ä LL</th>\n",
       "      <td>0.074706</td>\n",
       "      <td>-0.266723</td>\n",
       "      <td>0.105476</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>0.223364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>0.051346</td>\n",
       "      <td>-0.222668</td>\n",
       "      <td>0.427638</td>\n",
       "      <td>-0.127122</td>\n",
       "      <td>-0.093693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ä rock</th>\n",
       "      <td>-0.087891</td>\n",
       "      <td>-0.067962</td>\n",
       "      <td>0.227937</td>\n",
       "      <td>-0.006113</td>\n",
       "      <td>0.025071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.049320</td>\n",
       "      <td>-0.031832</td>\n",
       "      <td>0.147941</td>\n",
       "      <td>0.043445</td>\n",
       "      <td>0.030046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dim_0     dim_1     dim_2     dim_3     dim_4\n",
       "Open    0.094007 -0.323282  0.111917 -0.174867  0.205223\n",
       "-       0.085346 -0.068757 -0.038304 -0.102240  0.007169\n",
       "source -0.073628 -0.333408  0.051213 -0.093934  0.007476\n",
       "Ä LL     0.074706 -0.266723  0.105476  0.008115  0.223364\n",
       "Ms      0.051346 -0.222668  0.427638 -0.127122 -0.093693\n",
       "Ä rock  -0.087891 -0.067962  0.227937 -0.006113  0.025071\n",
       ".       0.049320 -0.031832  0.147941  0.043445  0.030046"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved to gpt2_block0_input_tensor.csv\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    input_tensor = model.wte(input_ids) + model.wpe(position_ids)\n",
    "input_tensor = input_tensor.squeeze(0)\n",
    "\n",
    "# Convert to numpy\n",
    "input_matrix = input_tensor.cpu().numpy()\n",
    "\n",
    "# Use tokens as index\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "df_input = pd.DataFrame(input_matrix, index=tokens)\n",
    "df_input.columns = [f\"dim_{i}\" for i in range(df_input.shape[1])]\n",
    "\n",
    "# Display first few dimensions\n",
    "display(df_input[[f\"dim_{i}\" for i in range(5)]])\n",
    "\n",
    "# Save to CSV\n",
    "df_input.to_csv(\"gpt2_block0_input_tensor.csv\", index_label=\"token\")\n",
    "print(\"âœ… Saved to gpt2_block0_input_tensor.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e4ee5b-cd44-420a-966d-4375bb08cb77",
   "metadata": {},
   "source": [
    "## Step 5: Caclulate input tensor and check difference with GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38bfc10a-3d7f-4f33-b2cb-0f83dddc2ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Max difference: 0.00000000\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    token_embeddings = model.wte(input_ids).squeeze(0)\n",
    "    pos_embeddings = model.wpe(position_ids).squeeze(0)\n",
    "    sum_manual = token_embeddings + pos_embeddings\n",
    "\n",
    "# Check max absolute difference\n",
    "diff = torch.abs(sum_manual - input_tensor).max().item()\n",
    "print(f\"âœ… Max difference: {diff:.8f}\")\n",
    "assert diff < 1e-6, \"âŒ Mismatch between summed embeddings and input tensor\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d3e35-0796-4866-9dd0-8730550adad7",
   "metadata": {},
   "source": [
    "## Step 6: We need to get the full Q K V weight matrices (which are split across 12 heads per block) for 12 blocks\n",
    "These are combined as one matrix 768x2034 and when split each of QKV are 768x768\n",
    "Each Q K V is then split across each of the 12 heads in each block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "837a4618-43be-48eb-b1ef-57a9cfd4ebf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved QKV weight matrices for block 0\n",
      "âœ… Saved QKV weight matrices for block 1\n",
      "âœ… Saved QKV weight matrices for block 2\n",
      "âœ… Saved QKV weight matrices for block 3\n",
      "âœ… Saved QKV weight matrices for block 4\n",
      "âœ… Saved QKV weight matrices for block 5\n",
      "âœ… Saved QKV weight matrices for block 6\n",
      "âœ… Saved QKV weight matrices for block 7\n",
      "âœ… Saved QKV weight matrices for block 8\n",
      "âœ… Saved QKV weight matrices for block 9\n",
      "âœ… Saved QKV weight matrices for block 10\n",
      "âœ… Saved QKV weight matrices for block 11\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(\"gpt2_weights\", exist_ok=True)\n",
    "\n",
    "# Loop through all 12 transformer blocks\n",
    "for i, block in enumerate(model.h):\n",
    "    # Get combined QKV weight: shape [768, 2304]\n",
    "    qkv_weight = block.attn.c_attn.weight.detach().cpu().numpy()\n",
    "\n",
    "    # Split into Q, K, V: each [768, 768]\n",
    "    W_Q, W_K, W_V = np.split(qkv_weight, 3, axis=1)\n",
    "\n",
    "    # Save each matrix\n",
    "    np.save(f\"gpt2_weights/block_{i}_W_Q.npy\", W_Q)\n",
    "    np.save(f\"gpt2_weights/block_{i}_W_K.npy\", W_K)\n",
    "    np.save(f\"gpt2_weights/block_{i}_W_V.npy\", W_V)\n",
    "\n",
    "    print(f\"âœ… Saved QKV weight matrices for block {i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48759b30-09bc-4614-aea6-34c1e1fc3a63",
   "metadata": {},
   "source": [
    "## Step 7: Let's get the biases for Q K V, learned starting points suggesting what Q K V should tend towards without even seeing the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca80c982-171e-44df-80b5-3ea6e101ad97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved QKV biases for block 0\n",
      "âœ… Saved QKV biases for block 1\n",
      "âœ… Saved QKV biases for block 2\n",
      "âœ… Saved QKV biases for block 3\n",
      "âœ… Saved QKV biases for block 4\n",
      "âœ… Saved QKV biases for block 5\n",
      "âœ… Saved QKV biases for block 6\n",
      "âœ… Saved QKV biases for block 7\n",
      "âœ… Saved QKV biases for block 8\n",
      "âœ… Saved QKV biases for block 9\n",
      "âœ… Saved QKV biases for block 10\n",
      "âœ… Saved QKV biases for block 11\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(\"gpt2_weights\", exist_ok=True)\n",
    "\n",
    "# Loop over all 12 transformer blocks\n",
    "for i, block in enumerate(model.h):\n",
    "    # Combined QKV bias: shape [2304]\n",
    "    qkv_bias = block.attn.c_attn.bias.detach().cpu().numpy()\n",
    "\n",
    "    # Split into Q, K, V: each [768]\n",
    "    b_Q, b_K, b_V = np.split(qkv_bias, 3)\n",
    "\n",
    "    # Save each bias\n",
    "    np.save(f\"gpt2_weights/block_{i}_b_Q.npy\", b_Q)\n",
    "    np.save(f\"gpt2_weights/block_{i}_b_K.npy\", b_K)\n",
    "    np.save(f\"gpt2_weights/block_{i}_b_V.npy\", b_V)\n",
    "\n",
    "    print(f\"âœ… Saved QKV biases for block {i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9671e8a-5ba8-43fd-9f89-19b9cfd8f597",
   "metadata": {},
   "source": [
    "## Step 8: Use a hook to get the Q K V block 0 GPT2 matrices for our input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8854db1b-f956-408e-8e73-b862a4f6bd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved Q, K, V matrices from GPT-2 block 0\n",
      "Q_ref shape: torch.Size([7, 768])\n",
      "K_ref shape: torch.Size([7, 768])\n",
      "V_ref shape: torch.Size([7, 768])\n",
      "\n",
      "Q_ref[0][:5]: tensor([-3.0921,  2.8398,  1.3211, -2.8124,  0.5560])\n",
      "K_ref[0][:5]: tensor([-11.1340,  16.9833,   9.8151,   1.2522,   5.7914])\n",
      "V_ref[0][:5]: tensor([ 0.1662, -0.0763,  0.2380,  0.1444, -0.0268])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with torch.no_grad():\n",
    "    qkv = model.h[0].attn.c_attn(input_tensor)  # shape: [seq_len, 2304]\n",
    "    Q_ref, K_ref, V_ref = torch.chunk(qkv, 3, dim=-1)  # each: [seq_len, 768]\n",
    "\n",
    "# Save to CSV\n",
    "pd.DataFrame(Q_ref).to_csv(\"gpt2_block0_Q_ref.csv\", index_label=\"token\")\n",
    "pd.DataFrame(K_ref).to_csv(\"gpt2_block0_K_ref.csv\", index_label=\"token\")\n",
    "pd.DataFrame(V_ref).to_csv(\"gpt2_block0_V_ref.csv\", index_label=\"token\")\n",
    "\n",
    "# Display shape and a sample\n",
    "print(\"âœ… Saved Q, K, V matrices from GPT-2 block 0\")\n",
    "print(f\"Q_ref shape: {Q_ref.shape}\")\n",
    "print(f\"K_ref shape: {K_ref.shape}\")\n",
    "print(f\"V_ref shape: {V_ref.shape}\\n\")\n",
    "\n",
    "# Show preview of first tokenâ€™s first 5 dimensions\n",
    "print(\"Q_ref[0][:5]:\", np.round(Q_ref[0][:5], 6))\n",
    "print(\"K_ref[0][:5]:\", np.round(K_ref[0][:5], 6))\n",
    "print(\"V_ref[0][:5]:\", np.round(V_ref[0][:5], 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f4a32e-764c-4f3b-a753-7904a844c549",
   "metadata": {},
   "source": [
    "## Step 9: Let's calculate Q K V for block 0 ourselves \n",
    "WWe are projecting the input tensor into three new planes using Q K V weight matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ba4c4cb-4255-43e8-9d5d-21850c82d8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q shape: torch.Size([7, 768])\n",
      "K shape: torch.Size([7, 768])\n",
      "V shape: torch.Size([7, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load input tensor (shape: [seq_len, hidden_size])\n",
    "# Assuming you've already defined `input_tensor` earlier:\n",
    "# If not, define it like this:\n",
    "# with torch.no_grad():\n",
    "#     input_tensor = model.wte(input_ids) + model.wpe(torch.arange(input_ids.shape[1]))\n",
    "\n",
    "# Load block 0 weights and biases\n",
    "W_Q = np.load(\"gpt2_weights/block_0_W_Q.npy\")\n",
    "W_K = np.load(\"gpt2_weights/block_0_W_K.npy\")\n",
    "W_V = np.load(\"gpt2_weights/block_0_W_V.npy\")\n",
    "\n",
    "b_Q = np.load(\"gpt2_weights/block_0_b_Q.npy\")\n",
    "b_K = np.load(\"gpt2_weights/block_0_b_K.npy\")\n",
    "b_V = np.load(\"gpt2_weights/block_0_b_V.npy\")\n",
    "\n",
    "# Convert to torch tensors\n",
    "W_Q = torch.tensor(W_Q, dtype=torch.float32)\n",
    "W_K = torch.tensor(W_K, dtype=torch.float32)\n",
    "W_V = torch.tensor(W_V, dtype=torch.float32)\n",
    "\n",
    "b_Q = torch.tensor(b_Q, dtype=torch.float32)\n",
    "b_K = torch.tensor(b_K, dtype=torch.float32)\n",
    "b_V = torch.tensor(b_V, dtype=torch.float32)\n",
    "\n",
    "# Project input to get Q, K, V (shape: [seq_len, hidden])\n",
    "Q = input_tensor @ W_Q + b_Q\n",
    "K = input_tensor @ W_K + b_K\n",
    "V = input_tensor @ W_V + b_V\n",
    "\n",
    "# Optional: check shapes\n",
    "print(\"Q shape:\", Q.shape)\n",
    "print(\"K shape:\", K.shape)\n",
    "print(\"V shape:\", V.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e727937-0320-41cd-9d83-53c1270f095d",
   "metadata": {},
   "source": [
    "## Step 10: Compare manual Q K V with GPT2 Q K V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f9ef02c-8727-4e4e-a78e-6c27993c8eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q diff (mean abs): 4.938428878046922e-07\n",
      "K diff (mean abs): 4.149513652007874e-07\n",
      "V diff (mean abs): 7.063186317529891e-08\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load reference QKV from model\n",
    "Q_ref = pd.read_csv(\"gpt2_block0_Q_ref.csv\", index_col=0).values\n",
    "K_ref = pd.read_csv(\"gpt2_block0_K_ref.csv\", index_col=0).values\n",
    "V_ref = pd.read_csv(\"gpt2_block0_V_ref.csv\", index_col=0).values\n",
    "\n",
    "# Compare with manually computed Q, K, V\n",
    "Q_manual = Q.numpy()\n",
    "K_manual = K.numpy()\n",
    "V_manual = V.numpy()\n",
    "\n",
    "# Compute differences\n",
    "print(\"Q diff (mean abs):\", np.mean(np.abs(Q_ref - Q_manual)))\n",
    "print(\"K diff (mean abs):\", np.mean(np.abs(K_ref - K_manual)))\n",
    "print(\"V diff (mean abs):\", np.mean(np.abs(V_ref - V_manual)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d50c8c-8a58-4908-b6f7-2ecaa4157f1f",
   "metadata": {},
   "source": [
    "## Step 11: Let's get GPT attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bf9ab44-47da-460a-a835-816975b44371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Captured attention output before projection (matches manual calc):\n",
      "tensor([[-0.0031,  0.0954, -0.0282, -0.0525, -0.0847, -0.3572, -0.0809, -0.1034,\n",
      "          0.0004,  0.0065],\n",
      "        [-0.0086,  0.0862, -0.0295, -0.0558, -0.0849, -0.3284, -0.0753, -0.0988,\n",
      "          0.0032, -0.0009],\n",
      "        [-0.0155,  0.0634, -0.0210, -0.0754, -0.0867, -0.3057, -0.0757, -0.1096,\n",
      "          0.0010, -0.0201],\n",
      "        [ 0.0547,  0.0341,  0.0691, -0.0647, -0.0633, -0.1771, -0.0393, -0.1540,\n",
      "          0.0169, -0.0618],\n",
      "        [ 0.0540,  0.0650,  0.0465, -0.0529, -0.0637, -0.2485, -0.0470, -0.1461,\n",
      "          0.0102, -0.0298]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import GPT2Model, GPT2TokenizerFast\n",
    "\n",
    "# --- Load model and tokenizer ---\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "model.eval()\n",
    "\n",
    "# --- Tokenize input ---\n",
    "sentence = \"open-source llms rock.\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False)\n",
    "\n",
    "# --- Dictionary to hold hook output ---\n",
    "raw_attn_output = {}\n",
    "\n",
    "# --- Define hook: grab input to `c_proj`, which is attention output before projection ---\n",
    "def hook_fn(module, input, output):\n",
    "    # input is a tuple â€” we take the tensor input to the c_proj layer\n",
    "    raw_attn_output[\"block1_attn_concat\"] = input[0].detach().squeeze(0)  # shape [seq_len, 768]\n",
    "\n",
    "# --- Register the hook on c_proj (linear output projection after attention) ---\n",
    "hook_handle = model.h[0].attn.c_proj.register_forward_hook(hook_fn)\n",
    "\n",
    "# --- Run the model ---\n",
    "with torch.no_grad():\n",
    "    _ = model(**inputs)\n",
    "\n",
    "# --- Remove hook after capturing ---\n",
    "hook_handle.remove()\n",
    "\n",
    "# --- Optional: Save or inspect result ---\n",
    "df = pd.DataFrame(raw_attn_output[\"block1_attn_concat\"].cpu().numpy())\n",
    "df.to_csv(\"gpt2_block1_attn_concat_output.csv\", index_label=\"token\")\n",
    "\n",
    "print(\"âœ… Captured attention output before projection (matches manual calc):\")\n",
    "print(raw_attn_output[\"block1_attn_concat\"][:5, :10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c89f71a-4086-4f28-973b-193a2703de33",
   "metadata": {},
   "source": [
    "## Step 12: Let's calculate attention using Q K V\n",
    "Q K V are tokens x 768 dimensinality, split to give 12 tokens by 64 heads, transpose to let each head see all tokens, compute attention head score matrix creating 12 tokens by tokens dimensionality attention scores, apply a causal mask, softmax over scores to produce attention probabilities for each token in the sequence, multiple by V, concatenate all heads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3324d573-a2ee-432b-b1af-54092d85d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Model, GPT2TokenizerFast\n",
    "\n",
    "# --- Load model and tokenizer ---\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "model.eval()\n",
    "\n",
    "# --- Tokenize correct input ---\n",
    "sentence = \"Open-source LLMs rock.\"  # ðŸ‘ˆ this exact string\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "seq_len = input_ids.shape[1]\n",
    "device = model.device\n",
    "\n",
    "# --- Hook to capture pre-projection attention output ---\n",
    "raw_attn_output = {}\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    raw_attn_output[\"block1_attn_concat\"] = input[0].detach().squeeze(0)\n",
    "\n",
    "hook_handle = model.h[0].attn.c_proj.register_forward_hook(hook_fn)\n",
    "\n",
    "# --- Run the model (trigger hook) ---\n",
    "with torch.no_grad():\n",
    "    _ = model(**inputs)\n",
    "\n",
    "hook_handle.remove()\n",
    "\n",
    "# --- MANUAL CALCULATION ---\n",
    "with torch.no_grad():\n",
    "    # Step 1: Input embeddings (token + position)\n",
    "    wte = model.wte(input_ids).squeeze(0)\n",
    "    wpe = model.wpe(torch.arange(seq_len, device=device)).squeeze(0)\n",
    "    input_tensor = wte + wpe  # [seq_len, hidden_size]\n",
    "\n",
    "    # Step 2: LayerNorm\n",
    "    ln_weight = model.h[0].ln_1.weight.detach()\n",
    "    ln_bias = model.h[0].ln_1.bias.detach()\n",
    "\n",
    "    def layer_norm(x, weight, bias, eps=1e-5):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, unbiased=False, keepdim=True)\n",
    "        return ((x - mean) / torch.sqrt(var + eps)) * weight + bias\n",
    "\n",
    "    x_norm = layer_norm(input_tensor, ln_weight, ln_bias)\n",
    "\n",
    "    # Step 3: QKV from single projection (GPT-2 uses c_attn)\n",
    "    W_full = model.h[0].attn.c_attn.weight.detach()\n",
    "    b_full = model.h[0].attn.c_attn.bias.detach()\n",
    "    qkv = x_norm @ W_full + b_full\n",
    "    Q, K, V = qkv.split(768, dim=-1)  # Each [seq_len, hidden]\n",
    "\n",
    "    # Step 4: Split into heads\n",
    "    num_heads = 12\n",
    "    head_dim = 64\n",
    "    def split_heads(x):\n",
    "        return x.view(seq_len, num_heads, head_dim).transpose(0, 1)  # [n_heads, seq_len, head_dim]\n",
    "\n",
    "    Q_heads = split_heads(Q)\n",
    "    K_heads = split_heads(K)\n",
    "    V_heads = split_heads(V)\n",
    "\n",
    "    # Step 5: Causal mask\n",
    "    mask = torch.tril(torch.ones(seq_len, seq_len, dtype=torch.bool, device=device))\n",
    "\n",
    "    # Step 6: Attention computation\n",
    "    attn_outputs = []\n",
    "    for i in range(num_heads):\n",
    "        q = Q_heads[i]  # [seq_len, head_dim]\n",
    "        k = K_heads[i]\n",
    "        v = V_heads[i]\n",
    "\n",
    "        scores = q @ k.T / (head_dim ** 0.5)\n",
    "        scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = weights @ v\n",
    "        attn_outputs.append(attn_output)\n",
    "\n",
    "    # Step 7: Concatenate heads\n",
    "    attn_concat = torch.cat(attn_outputs, dim=-1)  # [seq_len, hidden]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5114d54-4ae3-431f-938b-af6fe1232228",
   "metadata": {},
   "source": [
    "## Step 13: Now compare GPT2 layer 1 attention calculation with our manual attention calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba74b7be-0735-45d1-9b7c-25ea09cb80f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max diff: 8.344650268554688e-07\n",
      "Mean diff: 4.256519048340124e-08\n",
      "Allclose (1e-5)? True\n"
     ]
    }
   ],
   "source": [
    "# --- Final Comparison with hooked GPT-2 output ---\n",
    "diff = (attn_concat - raw_attn_output[\"block1_attn_concat\"]).abs()\n",
    "print(\"Max diff:\", diff.max().item())\n",
    "print(\"Mean diff:\", diff.mean().item())\n",
    "print(\"Allclose (1e-5)?\", torch.allclose(attn_concat, raw_attn_output[\"block1_attn_concat\"], atol=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94abde-dd8a-4ca8-8d93-8f2f1a21bdc6",
   "metadata": {},
   "source": [
    "## Step 14: Output projection (Mixing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "061bd34b-2465-425a-9e03-1a0db9b44d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Captured shape: torch.Size([7, 768])\n",
      "tensor([[ 1.3581, -0.6009,  0.3659, -0.0182,  0.0638],\n",
      "        [ 0.4536, -0.3578,  0.2065,  0.0037,  0.0930]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import GPT2Model, GPT2TokenizerFast\n",
    "\n",
    "# --- Load model and tokenizer ---\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "model.eval()\n",
    "\n",
    "# --- Tokenize your sentence once ---\n",
    "sentence = \"Open-source LLMs rock.\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False)\n",
    "\n",
    "# --- Hook dictionary ---\n",
    "mixed_output = {}\n",
    "\n",
    "# --- Hook function to capture output of c_proj (i.e., mixed attention) ---\n",
    "def cproj_hook(module, input, output):\n",
    "    mixed_output[\"block1_mixed\"] = output.detach().squeeze(0)\n",
    "\n",
    "# --- Register hook on block 1's c_proj ---\n",
    "hook_handle = model.h[0].attn.c_proj.register_forward_hook(cproj_hook)\n",
    "\n",
    "# --- Run the model to trigger the hook ---\n",
    "with torch.no_grad():\n",
    "    _ = model(**inputs)\n",
    "\n",
    "# --- Remove the hook after capturing the output ---\n",
    "hook_handle.remove()\n",
    "\n",
    "# --- Save to CSV or inspect ---\n",
    "df = pd.DataFrame(mixed_output[\"block1_mixed\"].cpu().numpy())\n",
    "df.to_csv(\"gpt2_block1_mixed_output.csv\", index_label=\"token\")\n",
    "\n",
    "# --- Optional: Inspect shape or values ---\n",
    "print(\"âœ… Captured shape:\", mixed_output[\"block1_mixed\"].shape)\n",
    "print(mixed_output[\"block1_mixed\"][:2, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d021935-02ee-47b2-ae07-96f57e36f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    manual_mixed = model.h[0].attn.c_proj(attn_concat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd2df246-18ea-4191-adfd-4e3feeeb87cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max diff: 5.7220458984375e-06\n",
      "Mean diff: 1.938748255270184e-07\n",
      "Allclose (1e-5)? True\n"
     ]
    }
   ],
   "source": [
    "diff = (manual_mixed - mixed_output[\"block1_mixed\"]).abs()\n",
    "print(\"Max diff:\", diff.max().item())\n",
    "print(\"Mean diff:\", diff.mean().item())\n",
    "print(\"Allclose (1e-5)?\", torch.allclose(manual_mixed, mixed_output[\"block1_mixed\"], atol=1e-5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef29b5d1-a61e-4595-b855-69983eeb706d",
   "metadata": {},
   "source": [
    "## Step 16: LayerNorm + MLP + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44910bd4-d035-48c6-a0cb-cf6940c927ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max diff: 1.52587890625e-05\n",
      "Mean diff: 7.624373665748863e-07\n",
      "Allclose (1e-5)? True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Model, GPT2TokenizerFast\n",
    "\n",
    "# Load model and tokenizer if not already loaded\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "model.eval()\n",
    "\n",
    "# Use your sentence\n",
    "sentence = \"Open-source LLMs rock.\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "seq_len = input_ids.shape[1]\n",
    "device = model.device\n",
    "\n",
    "# === EMBEDDING ===\n",
    "with torch.no_grad():\n",
    "    wte = model.wte(input_ids).squeeze(0)\n",
    "    wpe = model.wpe(torch.arange(seq_len, device=device)).squeeze(0)\n",
    "    input_tensor = wte + wpe  # [seq_len, hidden]\n",
    "\n",
    "# === LAYER NORM 1 ===\n",
    "def layer_norm(x, weight, bias, eps=1e-5):\n",
    "    mean = x.mean(-1, keepdim=True)\n",
    "    var = x.var(-1, unbiased=False, keepdim=True)\n",
    "    return ((x - mean) / torch.sqrt(var + eps)) * weight + bias\n",
    "\n",
    "ln1_weight = model.h[0].ln_1.weight.detach()\n",
    "ln1_bias = model.h[0].ln_1.bias.detach()\n",
    "x_norm = layer_norm(input_tensor, ln1_weight, ln1_bias)\n",
    "\n",
    "# === ATTENTION ===\n",
    "W_full = model.h[0].attn.c_attn.weight.detach()\n",
    "b_full = model.h[0].attn.c_attn.bias.detach()\n",
    "qkv = x_norm @ W_full + b_full\n",
    "Q, K, V = qkv.split(768, dim=-1)\n",
    "\n",
    "# Split into heads\n",
    "num_heads = 12\n",
    "head_dim = 64\n",
    "def split_heads(x):\n",
    "    return x.view(seq_len, num_heads, head_dim).transpose(0, 1)\n",
    "\n",
    "Q_heads = split_heads(Q)\n",
    "K_heads = split_heads(K)\n",
    "V_heads = split_heads(V)\n",
    "\n",
    "# Causal mask\n",
    "mask = torch.tril(torch.ones(seq_len, seq_len, dtype=torch.bool, device=device))\n",
    "\n",
    "# Scaled dot-product attention\n",
    "attn_outputs = []\n",
    "for i in range(num_heads):\n",
    "    q, k, v = Q_heads[i], K_heads[i], V_heads[i]\n",
    "    scores = q @ k.T / (head_dim ** 0.5)\n",
    "    scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    attn_output = weights @ v\n",
    "    attn_outputs.append(attn_output)\n",
    "\n",
    "# Concat heads and mix\n",
    "attn_concat = torch.cat(attn_outputs, dim=-1)  # [seq_len, hidden]\n",
    "manual_mixed = model.h[0].attn.c_proj(attn_concat)\n",
    "\n",
    "# === MANUAL BLOCK 1 COMPLETION ===\n",
    "\n",
    "# 1. Residual after attention\n",
    "x_resid1 = input_tensor + manual_mixed\n",
    "\n",
    "# 2. LayerNorm 2\n",
    "ln2_weight = model.h[0].ln_2.weight.detach()\n",
    "ln2_bias = model.h[0].ln_2.bias.detach()\n",
    "x_norm2 = layer_norm(x_resid1, ln2_weight, ln2_bias)\n",
    "\n",
    "# 3. MLP (feed-forward)\n",
    "mlp_out = model.h[0].mlp(x_norm2)\n",
    "\n",
    "# 4. Final residual\n",
    "block1_manual = x_resid1 + mlp_out  # [seq_len, hidden]\n",
    "\n",
    "# === GPT2 BLOCK 1 OUTPUT (actual) ===\n",
    "with torch.no_grad():\n",
    "    block1_out = model.h[0](input_tensor.unsqueeze(0))  # [1, seq_len, hidden] or nested tuple\n",
    "\n",
    "# Safely extract the real tensor\n",
    "while isinstance(block1_out, (tuple, list)):\n",
    "    block1_out = block1_out[0]\n",
    "block1_out = block1_out.squeeze(0)\n",
    "\n",
    "# === COMPARISON ===\n",
    "diff = (block1_manual - block1_out).abs()\n",
    "print(\"Max diff:\", diff.max().item())\n",
    "print(\"Mean diff:\", diff.mean().item())\n",
    "print(\"Allclose (1e-5)?\", torch.allclose(block1_manual, block1_out, atol=1e-5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bf968a-a494-4d62-a9aa-9721b9cdb066",
   "metadata": {},
   "source": [
    "## Move more quickly now we know what's going on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a64ef7f-b55c-46e0-9209-fb6e99f3f8c7",
   "metadata": {},
   "source": [
    "## Let's grab GPT2 layer 1 and compare to manual calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad08b59b-0244-4f84-b91d-eea005f2fd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1 Comparison Results:\n",
      "==================================================\n",
      "Max difference: 6.103515625e-05\n",
      "Mean difference: 6.612365837099787e-07\n",
      "Allclose (atol=1e-5)? True\n",
      "Allclose (atol=1e-4)? True\n",
      "\n",
      "Shape check:\n",
      "Manual output shape: torch.Size([7, 768])\n",
      "GPT-2 output shape: torch.Size([7, 768])\n",
      "\n",
      "First 5 values of manual output:\n",
      "tensor([ 1.3345, -0.3729,  1.1140,  0.0153,  0.9656])\n",
      "\n",
      "First 5 values of GPT-2 output:\n",
      "tensor([ 1.3345, -0.3729,  1.1140,  0.0153,  0.9656])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Model, GPT2TokenizerFast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "model.eval()\n",
    "\n",
    "# Tokenize input\n",
    "sentence = \"Open-source LLMs rock.\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "seq_len = input_ids.shape[1]\n",
    "device = model.device\n",
    "\n",
    "# === STEP 1: Get input to block 1 (output of block 0) ===\n",
    "with torch.no_grad():\n",
    "    # Get embeddings\n",
    "    wte = model.wte(input_ids).squeeze(0)\n",
    "    wpe = model.wpe(torch.arange(seq_len, device=device)).squeeze(0)\n",
    "    input_tensor = wte + wpe  # [seq_len, hidden_size]\n",
    "    \n",
    "    # Pass through block 0 to get input for block 1\n",
    "    block0_output = model.h[0](input_tensor.unsqueeze(0))\n",
    "    # Handle tuple output\n",
    "    while isinstance(block0_output, (tuple, list)):\n",
    "        block0_output = block0_output[0]\n",
    "    block0_output = block0_output.squeeze(0)  # This is the input to block 1\n",
    "\n",
    "# === STEP 2: Hook to capture GPT-2's actual block 1 output ===\n",
    "gpt2_block1_output = {}\n",
    "\n",
    "def block1_hook(module, input, output):\n",
    "    # Handle tuple output\n",
    "    if isinstance(output, tuple):\n",
    "        gpt2_block1_output[\"block1\"] = output[0].detach().squeeze(0)\n",
    "    else:\n",
    "        gpt2_block1_output[\"block1\"] = output.detach().squeeze(0)\n",
    "\n",
    "# Register hook on block 1\n",
    "hook_handle = model.h[1].register_forward_hook(block1_hook)\n",
    "\n",
    "# Run model to trigger hook\n",
    "with torch.no_grad():\n",
    "    _ = model(**inputs)\n",
    "\n",
    "# Remove hook\n",
    "hook_handle.remove()\n",
    "\n",
    "# === STEP 3: Manual calculation of block 1 ===\n",
    "\n",
    "# Layer norm function\n",
    "def layer_norm(x, weight, bias, eps=1e-5):\n",
    "    mean = x.mean(-1, keepdim=True)\n",
    "    var = x.var(-1, unbiased=False, keepdim=True)\n",
    "    return ((x - mean) / torch.sqrt(var + eps)) * weight + bias\n",
    "\n",
    "# 3.1: LayerNorm 1\n",
    "ln1_weight = model.h[1].ln_1.weight.detach()\n",
    "ln1_bias = model.h[1].ln_1.bias.detach()\n",
    "x_norm = layer_norm(block0_output, ln1_weight, ln1_bias)\n",
    "\n",
    "# 3.2: Get combined QKV weight and bias (the way GPT-2 stores them)\n",
    "W_full = model.h[1].attn.c_attn.weight.detach()\n",
    "b_full = model.h[1].attn.c_attn.bias.detach()\n",
    "\n",
    "# 3.3: Project to get Q, K, V using combined projection\n",
    "qkv = x_norm @ W_full + b_full\n",
    "Q, K, V = qkv.split(768, dim=-1)  # Each [seq_len, hidden]\n",
    "\n",
    "# 3.4: Split into heads\n",
    "num_heads = 12\n",
    "head_dim = 64\n",
    "\n",
    "def split_heads(x):\n",
    "    return x.view(seq_len, num_heads, head_dim).transpose(0, 1)  # [n_heads, seq_len, head_dim]\n",
    "\n",
    "Q_heads = split_heads(Q)\n",
    "K_heads = split_heads(K)\n",
    "V_heads = split_heads(V)\n",
    "\n",
    "# 3.5: Causal mask\n",
    "mask = torch.tril(torch.ones(seq_len, seq_len, dtype=torch.bool, device=device))\n",
    "\n",
    "# 3.6: Attention computation\n",
    "attn_outputs = []\n",
    "for i in range(num_heads):\n",
    "    q = Q_heads[i]  # [seq_len, head_dim]\n",
    "    k = K_heads[i]\n",
    "    v = V_heads[i]\n",
    "    \n",
    "    scores = q @ k.T / (head_dim ** 0.5)\n",
    "    scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    attn_output = weights @ v\n",
    "    attn_outputs.append(attn_output)\n",
    "\n",
    "# 3.7: Concatenate heads\n",
    "attn_concat = torch.cat(attn_outputs, dim=-1)  # [seq_len, hidden]\n",
    "\n",
    "# 3.8: Output projection (mixing) - manual calculation\n",
    "W_proj = model.h[1].attn.c_proj.weight.detach()\n",
    "b_proj = model.h[1].attn.c_proj.bias.detach()\n",
    "manual_mixed = attn_concat @ W_proj + b_proj\n",
    "\n",
    "# 3.9: Residual connection after attention\n",
    "x_resid1 = block0_output + manual_mixed\n",
    "\n",
    "# 3.10: LayerNorm 2\n",
    "ln2_weight = model.h[1].ln_2.weight.detach()\n",
    "ln2_bias = model.h[1].ln_2.bias.detach()\n",
    "x_norm2 = layer_norm(x_resid1, ln2_weight, ln2_bias)\n",
    "\n",
    "# 3.11: MLP (feed-forward) - manual calculation\n",
    "# GPT-2 MLP: Linear(768->3072) -> GELU -> Linear(3072->768)\n",
    "W_fc = model.h[1].mlp.c_fc.weight.detach()\n",
    "b_fc = model.h[1].mlp.c_fc.bias.detach()\n",
    "W_proj2 = model.h[1].mlp.c_proj.weight.detach()\n",
    "b_proj2 = model.h[1].mlp.c_proj.bias.detach()\n",
    "\n",
    "# First linear layer\n",
    "mlp_hidden = x_norm2 @ W_fc + b_fc\n",
    "\n",
    "# GELU activation\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "mlp_hidden = gelu(mlp_hidden)\n",
    "\n",
    "# Second linear layer\n",
    "mlp_out = mlp_hidden @ W_proj2 + b_proj2\n",
    "\n",
    "# 3.12: Final residual\n",
    "block1_manual = x_resid1 + mlp_out  # [seq_len, hidden]\n",
    "\n",
    "# === STEP 4: Comparison ===\n",
    "diff = (block1_manual - gpt2_block1_output[\"block1\"]).abs()\n",
    "print(\"Block 1 Comparison Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Max difference: {diff.max().item()}\")\n",
    "print(f\"Mean difference: {diff.mean().item()}\")\n",
    "print(f\"Allclose (atol=1e-5)? {torch.allclose(block1_manual, gpt2_block1_output['block1'], atol=1e-5)}\")\n",
    "print(f\"Allclose (atol=1e-4)? {torch.allclose(block1_manual, gpt2_block1_output['block1'], atol=1e-4)}\")\n",
    "\n",
    "# Additional diagnostics\n",
    "print(f\"\\nShape check:\")\n",
    "print(f\"Manual output shape: {block1_manual.shape}\")\n",
    "print(f\"GPT-2 output shape: {gpt2_block1_output['block1'].shape}\")\n",
    "\n",
    "# Show first few values for verification\n",
    "print(f\"\\nFirst 5 values of manual output:\")\n",
    "print(block1_manual[0, :5])\n",
    "print(f\"\\nFirst 5 values of GPT-2 output:\")\n",
    "print(gpt2_block1_output['block1'][0, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7111ff-fe84-47dc-af9a-f002af73d182",
   "metadata": {},
   "source": [
    "## Let's grab GPT2 block 2 output and compare to manual calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecc50f08-90c3-4fcc-b6ed-033b48b552fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 2 Comparison Results:\n",
      "==================================================\n",
      "Max difference: 0.000732421875\n",
      "Mean difference: 1.5148484635574277e-06\n",
      "Allclose (atol=1e-5)? True\n",
      "Allclose (atol=1e-4)? True\n",
      "\n",
      "Shape check:\n",
      "Manual output shape: torch.Size([7, 768])\n",
      "GPT-2 output shape: torch.Size([7, 768])\n",
      "\n",
      "First 5 values of manual output:\n",
      "tensor([ 1.3505, -0.3250,  0.9175,  0.1337,  1.1187])\n",
      "\n",
      "First 5 values of GPT-2 output:\n",
      "tensor([ 1.3505, -0.3250,  0.9175,  0.1337,  1.1187])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Model, GPT2TokenizerFast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "model.eval()\n",
    "\n",
    "# Tokenize input\n",
    "sentence = \"Open-source LLMs rock.\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "seq_len = input_ids.shape[1]\n",
    "device = model.device\n",
    "\n",
    "# Layer norm function\n",
    "def layer_norm(x, weight, bias, eps=1e-5):\n",
    "    mean = x.mean(-1, keepdim=True)\n",
    "    var = x.var(-1, unbiased=False, keepdim=True)\n",
    "    return ((x - mean) / torch.sqrt(var + eps)) * weight + bias\n",
    "\n",
    "# GELU activation\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "# Split heads function\n",
    "def split_heads(x, num_heads=12, head_dim=64):\n",
    "    return x.view(seq_len, num_heads, head_dim).transpose(0, 1)\n",
    "\n",
    "# === STEP 1: Run block 0 manually (from Step 16 in notebook) ===\n",
    "with torch.no_grad():\n",
    "    # Get embeddings\n",
    "    wte = model.wte(input_ids).squeeze(0)\n",
    "    wpe = model.wpe(torch.arange(seq_len, device=device)).squeeze(0)\n",
    "    input_tensor = wte + wpe  # [seq_len, hidden_size]\n",
    "    \n",
    "    # Block 0 computation (from Step 16)\n",
    "    # LayerNorm 1\n",
    "    ln1_weight = model.h[0].ln_1.weight.detach()\n",
    "    ln1_bias = model.h[0].ln_1.bias.detach()\n",
    "    x_norm = layer_norm(input_tensor, ln1_weight, ln1_bias)\n",
    "    \n",
    "    # QKV\n",
    "    W_full = model.h[0].attn.c_attn.weight.detach()\n",
    "    b_full = model.h[0].attn.c_attn.bias.detach()\n",
    "    qkv = x_norm @ W_full + b_full\n",
    "    Q, K, V = qkv.split(768, dim=-1)\n",
    "    \n",
    "    # Multi-head attention\n",
    "    num_heads = 12\n",
    "    head_dim = 64\n",
    "    Q_heads = split_heads(Q)\n",
    "    K_heads = split_heads(K)\n",
    "    V_heads = split_heads(V)\n",
    "    \n",
    "    mask = torch.tril(torch.ones(seq_len, seq_len, dtype=torch.bool, device=device))\n",
    "    \n",
    "    attn_outputs = []\n",
    "    for i in range(num_heads):\n",
    "        q, k, v = Q_heads[i], K_heads[i], V_heads[i]\n",
    "        scores = q @ k.T / (head_dim ** 0.5)\n",
    "        scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = weights @ v\n",
    "        attn_outputs.append(attn_output)\n",
    "    \n",
    "    attn_concat = torch.cat(attn_outputs, dim=-1)\n",
    "    manual_mixed = model.h[0].attn.c_proj(attn_concat)\n",
    "    \n",
    "    # Residual\n",
    "    x_resid1 = input_tensor + manual_mixed\n",
    "    \n",
    "    # LayerNorm 2\n",
    "    ln2_weight = model.h[0].ln_2.weight.detach()\n",
    "    ln2_bias = model.h[0].ln_2.bias.detach()\n",
    "    x_norm2 = layer_norm(x_resid1, ln2_weight, ln2_bias)\n",
    "    \n",
    "    # MLP\n",
    "    mlp_out = model.h[0].mlp(x_norm2)\n",
    "    \n",
    "    # Final residual\n",
    "    block0_manual = x_resid1 + mlp_out\n",
    "\n",
    "# === Run block 1 manually (using block0_manual as input) ===\n",
    "with torch.no_grad():\n",
    "    # LayerNorm 1\n",
    "    ln1_weight = model.h[1].ln_1.weight.detach()\n",
    "    ln1_bias = model.h[1].ln_1.bias.detach()\n",
    "    x_norm = layer_norm(block0_manual, ln1_weight, ln1_bias)\n",
    "    \n",
    "    # QKV\n",
    "    W_full = model.h[1].attn.c_attn.weight.detach()\n",
    "    b_full = model.h[1].attn.c_attn.bias.detach()\n",
    "    qkv = x_norm @ W_full + b_full\n",
    "    Q, K, V = qkv.split(768, dim=-1)\n",
    "    \n",
    "    # Multi-head attention\n",
    "    Q_heads = split_heads(Q)\n",
    "    K_heads = split_heads(K)\n",
    "    V_heads = split_heads(V)\n",
    "    \n",
    "    attn_outputs = []\n",
    "    for i in range(num_heads):\n",
    "        q, k, v = Q_heads[i], K_heads[i], V_heads[i]\n",
    "        scores = q @ k.T / (head_dim ** 0.5)\n",
    "        scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = weights @ v\n",
    "        attn_outputs.append(attn_output)\n",
    "    \n",
    "    attn_concat = torch.cat(attn_outputs, dim=-1)\n",
    "    \n",
    "    # Output projection - manual\n",
    "    W_proj = model.h[1].attn.c_proj.weight.detach()\n",
    "    b_proj = model.h[1].attn.c_proj.bias.detach()\n",
    "    manual_mixed = attn_concat @ W_proj + b_proj\n",
    "    \n",
    "    # Residual\n",
    "    x_resid1 = block0_manual + manual_mixed\n",
    "    \n",
    "    # LayerNorm 2\n",
    "    ln2_weight = model.h[1].ln_2.weight.detach()\n",
    "    ln2_bias = model.h[1].ln_2.bias.detach()\n",
    "    x_norm2 = layer_norm(x_resid1, ln2_weight, ln2_bias)\n",
    "    \n",
    "    # MLP - manual\n",
    "    W_fc = model.h[1].mlp.c_fc.weight.detach()\n",
    "    b_fc = model.h[1].mlp.c_fc.bias.detach()\n",
    "    W_proj2 = model.h[1].mlp.c_proj.weight.detach()\n",
    "    b_proj2 = model.h[1].mlp.c_proj.bias.detach()\n",
    "    \n",
    "    mlp_hidden = x_norm2 @ W_fc + b_fc\n",
    "    mlp_hidden = gelu(mlp_hidden)\n",
    "    mlp_out = mlp_hidden @ W_proj2 + b_proj2\n",
    "    \n",
    "    # Final residual\n",
    "    block1_manual = x_resid1 + mlp_out\n",
    "\n",
    "# === STEP 2: Hook to capture GPT-2's actual block 2 output ===\n",
    "gpt2_block2_output = {}\n",
    "\n",
    "def block2_hook(module, input, output):\n",
    "    if isinstance(output, tuple):\n",
    "        gpt2_block2_output[\"block2\"] = output[0].detach().squeeze(0)\n",
    "    else:\n",
    "        gpt2_block2_output[\"block2\"] = output.detach().squeeze(0)\n",
    "\n",
    "hook_handle = model.h[2].register_forward_hook(block2_hook)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model(**inputs)\n",
    "\n",
    "hook_handle.remove()\n",
    "\n",
    "# === STEP 3: Manual calculation of block 2 (using block1_manual as input) ===\n",
    "with torch.no_grad():\n",
    "    # LayerNorm 1\n",
    "    ln1_weight = model.h[2].ln_1.weight.detach()\n",
    "    ln1_bias = model.h[2].ln_1.bias.detach()\n",
    "    x_norm = layer_norm(block1_manual, ln1_weight, ln1_bias)\n",
    "    \n",
    "    # QKV\n",
    "    W_full = model.h[2].attn.c_attn.weight.detach()\n",
    "    b_full = model.h[2].attn.c_attn.bias.detach()\n",
    "    qkv = x_norm @ W_full + b_full\n",
    "    Q, K, V = qkv.split(768, dim=-1)\n",
    "    \n",
    "    # Multi-head attention\n",
    "    Q_heads = split_heads(Q)\n",
    "    K_heads = split_heads(K)\n",
    "    V_heads = split_heads(V)\n",
    "    \n",
    "    attn_outputs = []\n",
    "    for i in range(num_heads):\n",
    "        q, k, v = Q_heads[i], K_heads[i], V_heads[i]\n",
    "        scores = q @ k.T / (head_dim ** 0.5)\n",
    "        scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = weights @ v\n",
    "        attn_outputs.append(attn_output)\n",
    "    \n",
    "    attn_concat = torch.cat(attn_outputs, dim=-1)\n",
    "    \n",
    "    # Output projection - manual\n",
    "    W_proj = model.h[2].attn.c_proj.weight.detach()\n",
    "    b_proj = model.h[2].attn.c_proj.bias.detach()\n",
    "    manual_mixed = attn_concat @ W_proj + b_proj\n",
    "    \n",
    "    # Residual\n",
    "    x_resid1 = block1_manual + manual_mixed\n",
    "    \n",
    "    # LayerNorm 2\n",
    "    ln2_weight = model.h[2].ln_2.weight.detach()\n",
    "    ln2_bias = model.h[2].ln_2.bias.detach()\n",
    "    x_norm2 = layer_norm(x_resid1, ln2_weight, ln2_bias)\n",
    "    \n",
    "    # MLP - manual\n",
    "    W_fc = model.h[2].mlp.c_fc.weight.detach()\n",
    "    b_fc = model.h[2].mlp.c_fc.bias.detach()\n",
    "    W_proj2 = model.h[2].mlp.c_proj.weight.detach()\n",
    "    b_proj2 = model.h[2].mlp.c_proj.bias.detach()\n",
    "    \n",
    "    mlp_hidden = x_norm2 @ W_fc + b_fc\n",
    "    mlp_hidden = gelu(mlp_hidden)\n",
    "    mlp_out = mlp_hidden @ W_proj2 + b_proj2\n",
    "    \n",
    "    # Final residual\n",
    "    block2_manual = x_resid1 + mlp_out\n",
    "\n",
    "# === STEP 4: Comparison ===\n",
    "diff = (block2_manual - gpt2_block2_output[\"block2\"]).abs()\n",
    "print(\"Block 2 Comparison Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Max difference: {diff.max().item()}\")\n",
    "print(f\"Mean difference: {diff.mean().item()}\")\n",
    "print(f\"Allclose (atol=1e-5)? {torch.allclose(block2_manual, gpt2_block2_output['block2'], atol=1e-5)}\")\n",
    "print(f\"Allclose (atol=1e-4)? {torch.allclose(block2_manual, gpt2_block2_output['block2'], atol=1e-4)}\")\n",
    "\n",
    "print(f\"\\nShape check:\")\n",
    "print(f\"Manual output shape: {block2_manual.shape}\")\n",
    "print(f\"GPT-2 output shape: {gpt2_block2_output['block2'].shape}\")\n",
    "\n",
    "print(f\"\\nFirst 5 values of manual output:\")\n",
    "print(block2_manual[0, :5])\n",
    "print(f\"\\nFirst 5 values of GPT-2 output:\")\n",
    "print(gpt2_block2_output['block2'][0, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2077f0bc-ac54-4ece-a899-cbf623a2fdf6",
   "metadata": {},
   "source": [
    "## Let's grab GPT2 layer 3 and compare to manual calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4907bd7-6210-4a07-9c5c-920b1fd001f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 3 Comparison Results:\n",
      "==================================================\n",
      "Max difference: 0.000732421875\n",
      "Mean difference: 2.0162131022516405e-06\n",
      "Allclose (atol=1e-5)? True\n",
      "Allclose (atol=1e-4)? True\n",
      "\n",
      "Shape check:\n",
      "Manual output shape: torch.Size([7, 768])\n",
      "GPT-2 output shape: torch.Size([7, 768])\n",
      "\n",
      "First 5 values of manual output:\n",
      "tensor([ 1.3790, -0.3283,  0.9930,  0.1346,  1.2495])\n",
      "\n",
      "First 5 values of GPT-2 output:\n",
      "tensor([ 1.3790, -0.3283,  0.9930,  0.1346,  1.2495])\n"
     ]
    }
   ],
   "source": [
    "# === STEP: Hook to capture GPT-2's actual block 3 output ===\n",
    "gpt2_block3_output = {}\n",
    "\n",
    "def block3_hook(module, input, output):\n",
    "    if isinstance(output, tuple):\n",
    "        gpt2_block3_output[\"block3\"] = output[0].detach().squeeze(0)\n",
    "    else:\n",
    "        gpt2_block3_output[\"block3\"] = output.detach().squeeze(0)\n",
    "\n",
    "hook_handle = model.h[3].register_forward_hook(block3_hook)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model(**inputs)\n",
    "\n",
    "hook_handle.remove()\n",
    "\n",
    "# === STEP: Manual calculation of block 3 ===\n",
    "with torch.no_grad():\n",
    "    # LayerNorm 1\n",
    "    ln1_weight = model.h[3].ln_1.weight.detach()\n",
    "    ln1_bias = model.h[3].ln_1.bias.detach()\n",
    "    x_norm = layer_norm(block2_manual, ln1_weight, ln1_bias)\n",
    "\n",
    "    # QKV\n",
    "    W_full = model.h[3].attn.c_attn.weight.detach()\n",
    "    b_full = model.h[3].attn.c_attn.bias.detach()\n",
    "    qkv = x_norm @ W_full + b_full\n",
    "    Q, K, V = qkv.split(768, dim=-1)\n",
    "\n",
    "    # Multi-head attention\n",
    "    Q_heads = split_heads(Q)\n",
    "    K_heads = split_heads(K)\n",
    "    V_heads = split_heads(V)\n",
    "\n",
    "    attn_outputs = []\n",
    "    for i in range(num_heads):\n",
    "        q, k, v = Q_heads[i], K_heads[i], V_heads[i]\n",
    "        scores = q @ k.T / (head_dim ** 0.5)\n",
    "        scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = weights @ v\n",
    "        attn_outputs.append(attn_output)\n",
    "\n",
    "    attn_concat = torch.cat(attn_outputs, dim=-1)\n",
    "\n",
    "    # Output projection - manual\n",
    "    W_proj = model.h[3].attn.c_proj.weight.detach()\n",
    "    b_proj = model.h[3].attn.c_proj.bias.detach()\n",
    "    manual_mixed = attn_concat @ W_proj + b_proj\n",
    "\n",
    "    # Residual\n",
    "    x_resid1 = block2_manual + manual_mixed\n",
    "\n",
    "    # LayerNorm 2\n",
    "    ln2_weight = model.h[3].ln_2.weight.detach()\n",
    "    ln2_bias = model.h[3].ln_2.bias.detach()\n",
    "    x_norm2 = layer_norm(x_resid1, ln2_weight, ln2_bias)\n",
    "\n",
    "    # MLP - manual\n",
    "    W_fc = model.h[3].mlp.c_fc.weight.detach()\n",
    "    b_fc = model.h[3].mlp.c_fc.bias.detach()\n",
    "    W_proj2 = model.h[3].mlp.c_proj.weight.detach()\n",
    "    b_proj2 = model.h[3].mlp.c_proj.bias.detach()\n",
    "\n",
    "    mlp_hidden = x_norm2 @ W_fc + b_fc\n",
    "    mlp_hidden = gelu(mlp_hidden)\n",
    "    mlp_out = mlp_hidden @ W_proj2 + b_proj2\n",
    "\n",
    "    # Final residual\n",
    "    block3_manual = x_resid1 + mlp_out\n",
    "\n",
    "# === STEP: Comparison ===\n",
    "diff = (block3_manual - gpt2_block3_output[\"block3\"]).abs()\n",
    "print(\"Block 3 Comparison Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Max difference: {diff.max().item()}\")\n",
    "print(f\"Mean difference: {diff.mean().item()}\")\n",
    "print(f\"Allclose (atol=1e-5)? {torch.allclose(block3_manual, gpt2_block3_output['block3'], atol=1e-5)}\")\n",
    "print(f\"Allclose (atol=1e-4)? {torch.allclose(block3_manual, gpt2_block3_output['block3'], atol=1e-4)}\")\n",
    "\n",
    "print(f\"\\nShape check:\")\n",
    "print(f\"Manual output shape: {block3_manual.shape}\")\n",
    "print(f\"GPT-2 output shape: {gpt2_block3_output['block3'].shape}\")\n",
    "\n",
    "print(f\"\\nFirst 5 values of manual output:\")\n",
    "print(block3_manual[0, :5])\n",
    "print(f\"\\nFirst 5 values of GPT-2 output:\")\n",
    "print(gpt2_block3_output['block3'][0, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "092ae0d6-83d6-44eb-8492-49b3ec3d5452",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ## Let's grab GPT2 layer 4 and compare to manual calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "087d1197-89e7-4b23-b1c5-c7733fa2531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 4 Comparison Results:\n",
      "==================================================\n",
      "Max difference: 0.000732421875\n",
      "Mean difference: 2.339834281883668e-06\n",
      "Allclose (atol=1e-5)? True\n",
      "Allclose (atol=1e-4)? True\n",
      "\n",
      "Shape check:\n",
      "Manual output shape: torch.Size([7, 768])\n",
      "GPT-2 output shape: torch.Size([7, 768])\n",
      "\n",
      "First 5 values of manual output:\n",
      "tensor([ 1.2032, -0.3899,  0.9021,  0.0613,  1.2972])\n",
      "\n",
      "First 5 values of GPT-2 output:\n",
      "tensor([ 1.2032, -0.3899,  0.9021,  0.0613,  1.2972])\n"
     ]
    }
   ],
   "source": [
    "# === STEP: Hook to capture GPT-2's actual block 4 output ===\n",
    "gpt2_block4_output = {}\n",
    "\n",
    "def block4_hook(module, input, output):\n",
    "    if isinstance(output, tuple):\n",
    "        gpt2_block4_output[\"block4\"] = output[0].detach().squeeze(0)\n",
    "    else:\n",
    "        gpt2_block4_output[\"block4\"] = output.detach().squeeze(0)\n",
    "\n",
    "hook_handle = model.h[4].register_forward_hook(block4_hook)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model(**inputs)\n",
    "\n",
    "hook_handle.remove()\n",
    "\n",
    "# === STEP: Manual calculation of block 4 ===\n",
    "with torch.no_grad():\n",
    "    # LayerNorm 1\n",
    "    ln1_weight = model.h[4].ln_1.weight.detach()\n",
    "    ln1_bias = model.h[4].ln_1.bias.detach()\n",
    "    x_norm = layer_norm(block3_manual, ln1_weight, ln1_bias)\n",
    "\n",
    "    # QKV\n",
    "    W_full = model.h[4].attn.c_attn.weight.detach()\n",
    "    b_full = model.h[4].attn.c_attn.bias.detach()\n",
    "    qkv = x_norm @ W_full + b_full\n",
    "    Q, K, V = qkv.split(768, dim=-1)\n",
    "\n",
    "    # Multi-head attention\n",
    "    Q_heads = split_heads(Q)\n",
    "    K_heads = split_heads(K)\n",
    "    V_heads = split_heads(V)\n",
    "\n",
    "    attn_outputs = []\n",
    "    for i in range(num_heads):\n",
    "        q, k, v = Q_heads[i], K_heads[i], V_heads[i]\n",
    "        scores = q @ k.T / (head_dim ** 0.5)\n",
    "        scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = weights @ v\n",
    "        attn_outputs.append(attn_output)\n",
    "\n",
    "    attn_concat = torch.cat(attn_outputs, dim=-1)\n",
    "\n",
    "    # Output projection - manual\n",
    "    W_proj = model.h[4].attn.c_proj.weight.detach()\n",
    "    b_proj = model.h[4].attn.c_proj.bias.detach()\n",
    "    manual_mixed = attn_concat @ W_proj + b_proj\n",
    "\n",
    "    # Residual\n",
    "    x_resid1 = block3_manual + manual_mixed\n",
    "\n",
    "    # LayerNorm 2\n",
    "    ln2_weight = model.h[4].ln_2.weight.detach()\n",
    "    ln2_bias = model.h[4].ln_2.bias.detach()\n",
    "    x_norm2 = layer_norm(x_resid1, ln2_weight, ln2_bias)\n",
    "\n",
    "    # MLP - manual\n",
    "    W_fc = model.h[4].mlp.c_fc.weight.detach()\n",
    "    b_fc = model.h[4].mlp.c_fc.bias.detach()\n",
    "    W_proj2 = model.h[4].mlp.c_proj.weight.detach()\n",
    "    b_proj2 = model.h[4].mlp.c_proj.bias.detach()\n",
    "\n",
    "    mlp_hidden = x_norm2 @ W_fc + b_fc\n",
    "    mlp_hidden = gelu(mlp_hidden)\n",
    "    mlp_out = mlp_hidden @ W_proj2 + b_proj2\n",
    "\n",
    "    # Final residual\n",
    "    block4_manual = x_resid1 + mlp_out\n",
    "\n",
    "# === STEP: Comparison ===\n",
    "diff = (block4_manual - gpt2_block4_output[\"block4\"]).abs()\n",
    "print(\"Block 4 Comparison Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Max difference: {diff.max().item()}\")\n",
    "print(f\"Mean difference: {diff.mean().item()}\")\n",
    "print(f\"Allclose (atol=1e-5)? {torch.allclose(block4_manual, gpt2_block4_output['block4'], atol=1e-5)}\")\n",
    "print(f\"Allclose (atol=1e-4)? {torch.allclose(block4_manual, gpt2_block4_output['block4'], atol=1e-4)}\")\n",
    "\n",
    "print(f\"\\nShape check:\")\n",
    "print(f\"Manual output shape: {block4_manual.shape}\")\n",
    "print(f\"GPT-2 output shape: {gpt2_block4_output['block4'].shape}\")\n",
    "\n",
    "print(f\"\\nFirst 5 values of manual output:\")\n",
    "print(block4_manual[0, :5])\n",
    "print(f\"\\nFirst 5 values of GPT-2 output:\")\n",
    "print(gpt2_block4_output['block4'][0, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3632a76-56c2-4f21-96e2-620efb509d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's grab GPT2 layer 5 and compare to manual calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "697722af-69ef-4e43-96d2-fcd2a7dd1f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 5 Comparison Results:\n",
      "==================================================\n",
      "Max difference: 0.000732421875\n",
      "Mean difference: 2.6769591841002693e-06\n",
      "Allclose (atol=1e-5)? False\n",
      "Allclose (atol=1e-4)? True\n",
      "\n",
      "Shape check:\n",
      "Manual output shape: torch.Size([7, 768])\n",
      "GPT-2 output shape: torch.Size([7, 768])\n",
      "\n",
      "First 5 values of manual output:\n",
      "tensor([ 1.1781, -0.5091,  0.9690,  0.0742,  1.5109])\n",
      "\n",
      "First 5 values of GPT-2 output:\n",
      "tensor([ 1.1781, -0.5091,  0.9690,  0.0742,  1.5109])\n"
     ]
    }
   ],
   "source": [
    "# === STEP: Hook to capture GPT-2's actual block 5 output ===\n",
    "gpt2_block5_output = {}\n",
    "\n",
    "def block5_hook(module, input, output):\n",
    "    if isinstance(output, tuple):\n",
    "        gpt2_block5_output[\"block5\"] = output[0].detach().squeeze(0)\n",
    "    else:\n",
    "        gpt2_block5_output[\"block5\"] = output.detach().squeeze(0)\n",
    "\n",
    "hook_handle = model.h[5].register_forward_hook(block5_hook)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model(**inputs)\n",
    "\n",
    "hook_handle.remove()\n",
    "\n",
    "# === STEP: Manual calculation of block 5 ===\n",
    "with torch.no_grad():\n",
    "    # LayerNorm 1\n",
    "    ln1_weight = model.h[5].ln_1.weight.detach()\n",
    "    ln1_bias = model.h[5].ln_1.bias.detach()\n",
    "    x_norm = layer_norm(block4_manual, ln1_weight, ln1_bias)\n",
    "\n",
    "    # QKV\n",
    "    W_full = model.h[5].attn.c_attn.weight.detach()\n",
    "    b_full = model.h[5].attn.c_attn.bias.detach()\n",
    "    qkv = x_norm @ W_full + b_full\n",
    "    Q, K, V = qkv.split(768, dim=-1)\n",
    "\n",
    "    # Multi-head attention\n",
    "    Q_heads = split_heads(Q)\n",
    "    K_heads = split_heads(K)\n",
    "    V_heads = split_heads(V)\n",
    "\n",
    "    attn_outputs = []\n",
    "    for i in range(num_heads):\n",
    "        q, k, v = Q_heads[i], K_heads[i], V_heads[i]\n",
    "        scores = q @ k.T / (head_dim ** 0.5)\n",
    "        scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = weights @ v\n",
    "        attn_outputs.append(attn_output)\n",
    "\n",
    "    attn_concat = torch.cat(attn_outputs, dim=-1)\n",
    "\n",
    "    # Output projection - manual\n",
    "    W_proj = model.h[5].attn.c_proj.weight.detach()\n",
    "    b_proj = model.h[5].attn.c_proj.bias.detach()\n",
    "    manual_mixed = attn_concat @ W_proj + b_proj\n",
    "\n",
    "    # Residual\n",
    "    x_resid1 = block4_manual + manual_mixed\n",
    "\n",
    "    # LayerNorm 2\n",
    "    ln2_weight = model.h[5].ln_2.weight.detach()\n",
    "    ln2_bias = model.h[5].ln_2.bias.detach()\n",
    "    x_norm2 = layer_norm(x_resid1, ln2_weight, ln2_bias)\n",
    "\n",
    "    # MLP - manual\n",
    "    W_fc = model.h[5].mlp.c_fc.weight.detach()\n",
    "    b_fc = model.h[5].mlp.c_fc.bias.detach()\n",
    "    W_proj2 = model.h[5].mlp.c_proj.weight.detach()\n",
    "    b_proj2 = model.h[5].mlp.c_proj.bias.detach()\n",
    "\n",
    "    mlp_hidden = x_norm2 @ W_fc + b_fc\n",
    "    mlp_hidden = gelu(mlp_hidden)\n",
    "    mlp_out = mlp_hidden @ W_proj2 + b_proj2\n",
    "\n",
    "    # Final residual\n",
    "    block5_manual = x_resid1 + mlp_out\n",
    "\n",
    "# === STEP: Comparison ===\n",
    "diff = (block5_manual - gpt2_block5_output[\"block5\"]).abs()\n",
    "print(\"Block 5 Comparison Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Max difference: {diff.max().item()}\")\n",
    "print(f\"Mean difference: {diff.mean().item()}\")\n",
    "print(f\"Allclose (atol=1e-5)? {torch.allclose(block5_manual, gpt2_block5_output['block5'], atol=1e-5)}\")\n",
    "print(f\"Allclose (atol=1e-4)? {torch.allclose(block5_manual, gpt2_block5_output['block5'], atol=1e-4)}\")\n",
    "\n",
    "print(f\"\\nShape check:\")\n",
    "print(f\"Manual output shape: {block5_manual.shape}\")\n",
    "print(f\"GPT-2 output shape: {gpt2_block5_output['block5'].shape}\")\n",
    "\n",
    "print(f\"\\nFirst 5 values of manual output:\")\n",
    "print(block5_manual[0, :5])\n",
    "print(f\"\\nFirst 5 values of GPT-2 output:\")\n",
    "print(gpt2_block5_output['block5'][0, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4fa2cf5-7531-4314-bfca-5223d5a9b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Layer 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c21c7c1-0b2e-4f0e-b399-601526127362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 6 Comparison Results:\n",
      "==================================================\n",
      "Max difference: 0.000732421875\n",
      "Mean difference: 3.019989435415482e-06\n",
      "Allclose (atol=1e-5)? False\n",
      "Allclose (atol=1e-4)? True\n",
      "\n",
      "Shape check:\n",
      "Manual output shape: torch.Size([7, 768])\n",
      "GPT-2 output shape: torch.Size([7, 768])\n",
      "\n",
      "First 5 values of manual output:\n",
      "tensor([ 1.1117, -0.5070,  0.9983,  0.0067,  1.6709])\n",
      "\n",
      "First 5 values of GPT-2 output:\n",
      "tensor([ 1.1117, -0.5070,  0.9983,  0.0067,  1.6709])\n"
     ]
    }
   ],
   "source": [
    "# === STEP: Hook to capture GPT-2's actual block 6 output ===\n",
    "gpt2_block6_output = {}\n",
    "\n",
    "def block6_hook(module, input, output):\n",
    "    if isinstance(output, tuple):\n",
    "        gpt2_block6_output[\"block6\"] = output[0].detach().squeeze(0)\n",
    "    else:\n",
    "        gpt2_block6_output[\"block6\"] = output.detach().squeeze(0)\n",
    "\n",
    "hook_handle = model.h[6].register_forward_hook(block6_hook)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model(**inputs)\n",
    "\n",
    "hook_handle.remove()\n",
    "\n",
    "# === STEP: Manual calculation of block 6 ===\n",
    "with torch.no_grad():\n",
    "    # LayerNorm 1\n",
    "    ln1_weight = model.h[6].ln_1.weight.detach()\n",
    "    ln1_bias = model.h[6].ln_1.bias.detach()\n",
    "    x_norm = layer_norm(block5_manual, ln1_weight, ln1_bias)\n",
    "\n",
    "    # QKV\n",
    "    W_full = model.h[6].attn.c_attn.weight.detach()\n",
    "    b_full = model.h[6].attn.c_attn.bias.detach()\n",
    "    qkv = x_norm @ W_full + b_full\n",
    "    Q, K, V = qkv.split(768, dim=-1)\n",
    "\n",
    "    # Multi-head attention\n",
    "    Q_heads = split_heads(Q)\n",
    "    K_heads = split_heads(K)\n",
    "    V_heads = split_heads(V)\n",
    "\n",
    "    attn_outputs = []\n",
    "    for i in range(num_heads):\n",
    "        q, k, v = Q_heads[i], K_heads[i], V_heads[i]\n",
    "        scores = q @ k.T / (head_dim ** 0.5)\n",
    "        scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = weights @ v\n",
    "        attn_outputs.append(attn_output)\n",
    "\n",
    "    attn_concat = torch.cat(attn_outputs, dim=-1)\n",
    "\n",
    "    # Output projection - manual\n",
    "    W_proj = model.h[6].attn.c_proj.weight.detach()\n",
    "    b_proj = model.h[6].attn.c_proj.bias.detach()\n",
    "    manual_mixed = attn_concat @ W_proj + b_proj\n",
    "\n",
    "    # Residual\n",
    "    x_resid1 = block5_manual + manual_mixed\n",
    "\n",
    "    # LayerNorm 2\n",
    "    ln2_weight = model.h[6].ln_2.weight.detach()\n",
    "    ln2_bias = model.h[6].ln_2.bias.detach()\n",
    "    x_norm2 = layer_norm(x_resid1, ln2_weight, ln2_bias)\n",
    "\n",
    "    # MLP - manual\n",
    "    W_fc = model.h[6].mlp.c_fc.weight.detach()\n",
    "    b_fc = model.h[6].mlp.c_fc.bias.detach()\n",
    "    W_proj2 = model.h[6].mlp.c_proj.weight.detach()\n",
    "    b_proj2 = model.h[6].mlp.c_proj.bias.detach()\n",
    "\n",
    "    mlp_hidden = x_norm2 @ W_fc + b_fc\n",
    "    mlp_hidden = gelu(mlp_hidden)\n",
    "    mlp_out = mlp_hidden @ W_proj2 + b_proj2\n",
    "\n",
    "    # Final residual\n",
    "    block6_manual = x_resid1 + mlp_out\n",
    "\n",
    "# === STEP: Comparison ===\n",
    "diff = (block6_manual - gpt2_block6_output[\"block6\"]).abs()\n",
    "print(\"Block 6 Comparison Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Max difference: {diff.max().item()}\")\n",
    "print(f\"Mean difference: {diff.mean().item()}\")\n",
    "print(f\"Allclose (atol=1e-5)? {torch.allclose(block6_manual, gpt2_block6_output['block6'], atol=1e-5)}\")\n",
    "print(f\"Allclose (atol=1e-4)? {torch.allclose(block6_manual, gpt2_block6_output['block6'], atol=1e-4)}\")\n",
    "\n",
    "print(f\"\\nShape check:\")\n",
    "print(f\"Manual output shape: {block6_manual.shape}\")\n",
    "print(f\"GPT-2 output shape: {gpt2_block6_output['block6'].shape}\")\n",
    "\n",
    "print(f\"\\nFirst 5 values of manual output:\")\n",
    "print(block6_manual[0, :5])\n",
    "print(f\"\\nFirst 5 values of GPT-2 output:\")\n",
    "print(gpt2_block6_output['block6'][0, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b83c753f-00dd-4381-b51a-9e86ace65135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 7 Comparison Results:\n",
      "==================================================\n",
      "Max difference: 0.000732421875\n",
      "Mean difference: 3.427066076255869e-06\n",
      "Allclose (atol=1e-5)? False\n",
      "Allclose (atol=1e-4)? True\n",
      "\n",
      "Shape check:\n",
      "Manual output shape: torch.Size([7, 768])\n",
      "GPT-2 output shape: torch.Size([7, 768])\n",
      "\n",
      "First 5 values of manual output:\n",
      "tensor([ 1.0447, -0.3819,  0.8458, -0.1170,  1.7977])\n",
      "\n",
      "First 5 values of GPT-2 output:\n",
      "tensor([ 1.0447, -0.3819,  0.8458, -0.1170,  1.7977])\n"
     ]
    }
   ],
   "source": [
    "# === STEP: Hook to capture GPT-2's actual block 7 output ===\n",
    "gpt2_block7_output = {}\n",
    "\n",
    "def block7_hook(module, input, output):\n",
    "    if isinstance(output, tuple):\n",
    "        gpt2_block7_output[\"block7\"] = output[0].detach().squeeze(0)\n",
    "    else:\n",
    "        gpt2_block7_output[\"block7\"] = output.detach().squeeze(0)\n",
    "\n",
    "hook_handle = model.h[7].register_forward_hook(block7_hook)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model(**inputs)\n",
    "\n",
    "hook_handle.remove()\n",
    "\n",
    "# === STEP: Manual calculation of block 7 ===\n",
    "with torch.no_grad():\n",
    "    # LayerNorm 1\n",
    "    ln1_weight = model.h[7].ln_1.weight.detach()\n",
    "    ln1_bias = model.h[7].ln_1.bias.detach()\n",
    "    x_norm = layer_norm(block6_manual, ln1_weight, ln1_bias)\n",
    "\n",
    "    # QKV\n",
    "    W_full = model.h[7].attn.c_attn.weight.detach()\n",
    "    b_full = model.h[7].attn.c_attn.bias.detach()\n",
    "    qkv = x_norm @ W_full + b_full\n",
    "    Q, K, V = qkv.split(768, dim=-1)\n",
    "\n",
    "    # Multi-head attention\n",
    "    Q_heads = split_heads(Q)\n",
    "    K_heads = split_heads(K)\n",
    "    V_heads = split_heads(V)\n",
    "\n",
    "    attn_outputs = []\n",
    "    for i in range(num_heads):\n",
    "        q, k, v = Q_heads[i], K_heads[i], V_heads[i]\n",
    "        scores = q @ k.T / (head_dim ** 0.5)\n",
    "        scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = weights @ v\n",
    "        attn_outputs.append(attn_output)\n",
    "\n",
    "    attn_concat = torch.cat(attn_outputs, dim=-1)\n",
    "\n",
    "    # Output projection - manual\n",
    "    W_proj = model.h[7].attn.c_proj.weight.detach()\n",
    "    b_proj = model.h[7].attn.c_proj.bias.detach()\n",
    "    manual_mixed = attn_concat @ W_proj + b_proj\n",
    "\n",
    "    # Residual\n",
    "    x_resid1 = block6_manual + manual_mixed\n",
    "\n",
    "    # LayerNorm 2\n",
    "    ln2_weight = model.h[7].ln_2.weight.detach()\n",
    "    ln2_bias = model.h[7].ln_2.bias.detach()\n",
    "    x_norm2 = layer_norm(x_resid1, ln2_weight, ln2_bias)\n",
    "\n",
    "    # MLP - manual\n",
    "    W_fc = model.h[7].mlp.c_fc.weight.detach()\n",
    "    b_fc = model.h[7].mlp.c_fc.bias.detach()\n",
    "    W_proj2 = model.h[7].mlp.c_proj.weight.detach()\n",
    "    b_proj2 = model.h[7].mlp.c_proj.bias.detach()\n",
    "\n",
    "    mlp_hidden = x_norm2 @ W_fc + b_fc\n",
    "    mlp_hidden = gelu(mlp_hidden)\n",
    "    mlp_out = mlp_hidden @ W_proj2 + b_proj2\n",
    "\n",
    "    # Final residual\n",
    "    block7_manual = x_resid1 + mlp_out\n",
    "\n",
    "# === STEP: Comparison ===\n",
    "diff = (block7_manual - gpt2_block7_output[\"block7\"]).abs()\n",
    "print(\"Block 7 Comparison Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Max difference: {diff.max().item()}\")\n",
    "print(f\"Mean difference: {diff.mean().item()}\")\n",
    "print(f\"Allclose (atol=1e-5)? {torch.allclose(block7_manual, gpt2_block7_output['block7'], atol=1e-5)}\")\n",
    "print(f\"Allclose (atol=1e-4)? {torch.allclose(block7_manual, gpt2_block7_output['block7'], atol=1e-4)}\")\n",
    "\n",
    "print(f\"\\nShape check:\")\n",
    "print(f\"Manual output shape: {block7_manual.shape}\")\n",
    "print(f\"GPT-2 output shape: {gpt2_block7_output['block7'].shape}\")\n",
    "\n",
    "print(f\"\\nFirst 5 values of manual output:\")\n",
    "print(block7_manual[0, :5])\n",
    "print(f\"\\nFirst 5 values of GPT-2 output:\")\n",
    "print(gpt2_block7_output['block7'][0, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ec41a9f-6f84-42ab-88fd-b43ad26cfd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 8 Comparison Results:\n",
      "==================================================\n",
      "Max difference: 0.000732421875\n",
      "Mean difference: 4.001936758868396e-06\n",
      "Allclose (atol=1e-5)? False\n",
      "Allclose (atol=1e-4)? True\n",
      "\n",
      "Shape check:\n",
      "Manual output shape: torch.Size([7, 768])\n",
      "GPT-2 output shape: torch.Size([7, 768])\n",
      "\n",
      "First 5 values of manual output:\n",
      "tensor([ 1.1141, -0.3506,  0.8414, -0.2093,  1.7509])\n",
      "\n",
      "First 5 values of GPT-2 output:\n",
      "tensor([ 1.1141, -0.3506,  0.8414, -0.2093,  1.7509])\n"
     ]
    }
   ],
   "source": [
    "# === STEP: Hook to capture GPT-2's actual block 8 output ===\n",
    "gpt2_block8_output = {}\n",
    "\n",
    "def block8_hook(module, input, output):\n",
    "    if isinstance(output, tuple):\n",
    "        gpt2_block8_output[\"block8\"] = output[0].detach().squeeze(0)\n",
    "    else:\n",
    "        gpt2_block8_output[\"block8\"] = output.detach().squeeze(0)\n",
    "\n",
    "hook_handle = model.h[8].register_forward_hook(block8_hook)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model(**inputs)\n",
    "\n",
    "hook_handle.remove()\n",
    "\n",
    "# === STEP: Manual calculation of block 8 ===\n",
    "with torch.no_grad():\n",
    "    # LayerNorm 1\n",
    "    ln1_weight = model.h[8].ln_1.weight.detach()\n",
    "    ln1_bias = model.h[8].ln_1.bias.detach()\n",
    "    x_norm = layer_norm(block7_manual, ln1_weight, ln1_bias)\n",
    "\n",
    "    # QKV\n",
    "    W_full = model.h[8].attn.c_attn.weight.detach()\n",
    "    b_full = model.h[8].attn.c_attn.bias.detach()\n",
    "    qkv = x_norm @ W_full + b_full\n",
    "    Q, K, V = qkv.split(768, dim=-1)\n",
    "\n",
    "    # Multi-head attention\n",
    "    Q_heads = split_heads(Q)\n",
    "    K_heads = split_heads(K)\n",
    "    V_heads = split_heads(V)\n",
    "\n",
    "    attn_outputs = []\n",
    "    for i in range(num_heads):\n",
    "        q, k, v = Q_heads[i], K_heads[i], V_heads[i]\n",
    "        scores = q @ k.T / (head_dim ** 0.5)\n",
    "        scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = weights @ v\n",
    "        attn_outputs.append(attn_output)\n",
    "\n",
    "    attn_concat = torch.cat(attn_outputs, dim=-1)\n",
    "\n",
    "    # Output projection - manual\n",
    "    W_proj = model.h[8].attn.c_proj.weight.detach()\n",
    "    b_proj = model.h[8].attn.c_proj.bias.detach()\n",
    "    manual_mixed = attn_concat @ W_proj + b_proj\n",
    "\n",
    "    # Residual\n",
    "    x_resid1 = block7_manual + manual_mixed\n",
    "\n",
    "    # LayerNorm 2\n",
    "    ln2_weight = model.h[8].ln_2.weight.detach()\n",
    "    ln2_bias = model.h[8].ln_2.bias.detach()\n",
    "    x_norm2 = layer_norm(x_resid1, ln2_weight, ln2_bias)\n",
    "\n",
    "    # MLP - manual\n",
    "    W_fc = model.h[8].mlp.c_fc.weight.detach()\n",
    "    b_fc = model.h[8].mlp.c_fc.bias.detach()\n",
    "    W_proj2 = model.h[8].mlp.c_proj.weight.detach()\n",
    "    b_proj2 = model.h[8].mlp.c_proj.bias.detach()\n",
    "\n",
    "    mlp_hidden = x_norm2 @ W_fc + b_fc\n",
    "    mlp_hidden = gelu(mlp_hidden)\n",
    "    mlp_out = mlp_hidden @ W_proj2 + b_proj2\n",
    "\n",
    "    # Final residual\n",
    "    block8_manual = x_resid1 + mlp_out\n",
    "\n",
    "# === STEP: Comparison ===\n",
    "diff = (block8_manual - gpt2_block8_output[\"block8\"]).abs()\n",
    "print(\"Block 8 Comparison Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Max difference: {diff.max().item()}\")\n",
    "print(f\"Mean difference: {diff.mean().item()}\")\n",
    "print(f\"Allclose (atol=1e-5)? {torch.allclose(block8_manual, gpt2_block8_output['block8'], atol=1e-5)}\")\n",
    "print(f\"Allclose (atol=1e-4)? {torch.allclose(block8_manual, gpt2_block8_output['block8'], atol=1e-4)}\")\n",
    "\n",
    "print(f\"\\nShape check:\")\n",
    "print(f\"Manual output shape: {block8_manual.shape}\")\n",
    "print(f\"GPT-2 output shape: {gpt2_block8_output['block8'].shape}\")\n",
    "\n",
    "print(f\"\\nFirst 5 values of manual output:\")\n",
    "print(block8_manual[0, :5])\n",
    "print(f\"\\nFirst 5 values of GPT-2 output:\")\n",
    "print(gpt2_block8_output['block8'][0, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "876b8bf2-2914-4a0a-9298-cd2cee487e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Block 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "774934b1-a117-44c7-8b6b-6cb134c83de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 Comparison Results:\n",
      "==================================================\n",
      "Max difference: 0.000732421875\n",
      "Mean difference: 4.653896667150548e-06\n",
      "Allclose (atol=1e-5)? False\n",
      "Allclose (atol=1e-4)? True\n",
      "\n",
      "Shape check:\n",
      "Manual output shape: torch.Size([7, 768])\n",
      "GPT-2 output shape: torch.Size([7, 768])\n",
      "\n",
      "First 5 values of manual output:\n",
      "tensor([ 1.0533, -0.2555,  0.5720, -0.3252,  1.8056])\n",
      "\n",
      "First 5 values of GPT-2 output:\n",
      "tensor([ 1.0533, -0.2555,  0.5720, -0.3252,  1.8056])\n"
     ]
    }
   ],
   "source": [
    "# === STEP: Hook to capture GPT-2's actual block 9 output ===\n",
    "gpt2_block9_output = {}\n",
    "\n",
    "def block9_hook(module, input, output):\n",
    "    if isinstance(output, tuple):\n",
    "        gpt2_block9_output[\"block9\"] = output[0].detach().squeeze(0)\n",
    "    else:\n",
    "        gpt2_block9_output[\"block9\"] = output.detach().squeeze(0)\n",
    "\n",
    "hook_handle = model.h[9].register_forward_hook(block9_hook)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model(**inputs)\n",
    "\n",
    "hook_handle.remove()\n",
    "\n",
    "# === STEP: Manual calculation of block 9 ===\n",
    "with torch.no_grad():\n",
    "    # LayerNorm 1\n",
    "    ln1_weight = model.h[9].ln_1.weight.detach()\n",
    "    ln1_bias = model.h[9].ln_1.bias.detach()\n",
    "    x_norm = layer_norm(block8_manual, ln1_weight, ln1_bias)\n",
    "\n",
    "    # QKV\n",
    "    W_full = model.h[9].attn.c_attn.weight.detach()\n",
    "    b_full = model.h[9].attn.c_attn.bias.detach()\n",
    "    qkv = x_norm @ W_full + b_full\n",
    "    Q, K, V = qkv.split(768, dim=-1)\n",
    "\n",
    "    # Multi-head attention\n",
    "    Q_heads = split_heads(Q)\n",
    "    K_heads = split_heads(K)\n",
    "    V_heads = split_heads(V)\n",
    "\n",
    "    attn_outputs = []\n",
    "    for i in range(num_heads):\n",
    "        q, k, v = Q_heads[i], K_heads[i], V_heads[i]\n",
    "        scores = q @ k.T / (head_dim ** 0.5)\n",
    "        scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = weights @ v\n",
    "        attn_outputs.append(attn_output)\n",
    "\n",
    "    attn_concat = torch.cat(attn_outputs, dim=-1)\n",
    "\n",
    "    # Output projection - manual\n",
    "    W_proj = model.h[9].attn.c_proj.weight.detach()\n",
    "    b_proj = model.h[9].attn.c_proj.bias.detach()\n",
    "    manual_mixed = attn_concat @ W_proj + b_proj\n",
    "\n",
    "    # Residual\n",
    "    x_resid1 = block8_manual + manual_mixed\n",
    "\n",
    "    # LayerNorm 2\n",
    "    ln2_weight = model.h[9].ln_2.weight.detach()\n",
    "    ln2_bias = model.h[9].ln_2.bias.detach()\n",
    "    x_norm2 = layer_norm(x_resid1, ln2_weight, ln2_bias)\n",
    "\n",
    "    # MLP - manual\n",
    "    W_fc = model.h[9].mlp.c_fc.weight.detach()\n",
    "    b_fc = model.h[9].mlp.c_fc.bias.detach()\n",
    "    W_proj2 = model.h[9].mlp.c_proj.weight.detach()\n",
    "    b_proj2 = model.h[9].mlp.c_proj.bias.detach()\n",
    "\n",
    "    mlp_hidden = x_norm2 @ W_fc + b_fc\n",
    "    mlp_hidden = gelu(mlp_hidden)\n",
    "    mlp_out = mlp_hidden @ W_proj2 + b_proj2\n",
    "\n",
    "    # Final residual\n",
    "    block9_manual = x_resid1 + mlp_out\n",
    "\n",
    "# === STEP: Comparison ===\n",
    "diff = (block9_manual - gpt2_block9_output[\"block9\"]).abs()\n",
    "print(\"Block 9 Comparison Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Max difference: {diff.max().item()}\")\n",
    "print(f\"Mean difference: {diff.mean().item()}\")\n",
    "print(f\"Allclose (atol=1e-5)? {torch.allclose(block9_manual, gpt2_block9_output['block9'], atol=1e-5)}\")\n",
    "print(f\"Allclose (atol=1e-4)? {torch.allclose(block9_manual, gpt2_block9_output['block9'], atol=1e-4)}\")\n",
    "\n",
    "print(f\"\\nShape check:\")\n",
    "print(f\"Manual output shape: {block9_manual.shape}\")\n",
    "print(f\"GPT-2 output shape: {gpt2_block9_output['block9'].shape}\")\n",
    "\n",
    "print(f\"\\nFirst 5 values of manual output:\")\n",
    "print(block9_manual[0, :5])\n",
    "print(f\"\\nFirst 5 values of GPT-2 output:\")\n",
    "print(gpt2_block9_output['block9'][0, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d1b14361-3a63-446a-beb6-4f4aeb0b5b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 10 Comparison Results:\n",
      "==================================================\n",
      "Max difference: 0.00048828125\n",
      "Mean difference: 5.560018962569302e-06\n",
      "Allclose (atol=1e-5)? False\n",
      "Allclose (atol=1e-4)? True\n",
      "\n",
      "Shape check:\n",
      "Manual output shape: torch.Size([7, 768])\n",
      "GPT-2 output shape: torch.Size([7, 768])\n",
      "\n",
      "First 5 values of manual output:\n",
      "tensor([ 0.9528, -0.0858,  0.3158, -0.3833,  1.8234])\n",
      "\n",
      "First 5 values of GPT-2 output:\n",
      "tensor([ 0.9528, -0.0858,  0.3158, -0.3833,  1.8234])\n"
     ]
    }
   ],
   "source": [
    "# === STEP: Hook to capture GPT-2's actual block 10 output ===\n",
    "gpt2_block10_output = {}\n",
    "\n",
    "def block10_hook(module, input, output):\n",
    "    if isinstance(output, tuple):\n",
    "        gpt2_block10_output[\"block10\"] = output[0].detach().squeeze(0)\n",
    "    else:\n",
    "        gpt2_block10_output[\"block10\"] = output.detach().squeeze(0)\n",
    "\n",
    "hook_handle = model.h[10].register_forward_hook(block10_hook)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model(**inputs)\n",
    "\n",
    "hook_handle.remove()\n",
    "\n",
    "# === STEP: Manual calculation of block 10 ===\n",
    "with torch.no_grad():\n",
    "    # LayerNorm 1\n",
    "    ln1_weight = model.h[10].ln_1.weight.detach()\n",
    "    ln1_bias = model.h[10].ln_1.bias.detach()\n",
    "    x_norm = layer_norm(block9_manual, ln1_weight, ln1_bias)\n",
    "\n",
    "    # QKV\n",
    "    W_full = model.h[10].attn.c_attn.weight.detach()\n",
    "    b_full = model.h[10].attn.c_attn.bias.detach()\n",
    "    qkv = x_norm @ W_full + b_full\n",
    "    Q, K, V = qkv.split(768, dim=-1)\n",
    "\n",
    "    # Multi-head attention\n",
    "    Q_heads = split_heads(Q)\n",
    "    K_heads = split_heads(K)\n",
    "    V_heads = split_heads(V)\n",
    "\n",
    "    attn_outputs = []\n",
    "    for i in range(num_heads):\n",
    "        q, k, v = Q_heads[i], K_heads[i], V_heads[i]\n",
    "        scores = q @ k.T / (head_dim ** 0.5)\n",
    "        scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = weights @ v\n",
    "        attn_outputs.append(attn_output)\n",
    "\n",
    "    attn_concat = torch.cat(attn_outputs, dim=-1)\n",
    "\n",
    "    # Output projection - manual\n",
    "    W_proj = model.h[10].attn.c_proj.weight.detach()\n",
    "    b_proj = model.h[10].attn.c_proj.bias.detach()\n",
    "    manual_mixed = attn_concat @ W_proj + b_proj\n",
    "\n",
    "    # Residual\n",
    "    x_resid1 = block9_manual + manual_mixed\n",
    "\n",
    "    # LayerNorm 2\n",
    "    ln2_weight = model.h[10].ln_2.weight.detach()\n",
    "    ln2_bias = model.h[10].ln_2.bias.detach()\n",
    "    x_norm2 = layer_norm(x_resid1, ln2_weight, ln2_bias)\n",
    "\n",
    "    # MLP - manual\n",
    "    W_fc = model.h[10].mlp.c_fc.weight.detach()\n",
    "    b_fc = model.h[10].mlp.c_fc.bias.detach()\n",
    "    W_proj2 = model.h[10].mlp.c_proj.weight.detach()\n",
    "    b_proj2 = model.h[10].mlp.c_proj.bias.detach()\n",
    "\n",
    "    mlp_hidden = x_norm2 @ W_fc + b_fc\n",
    "    mlp_hidden = gelu(mlp_hidden)\n",
    "    mlp_out = mlp_hidden @ W_proj2 + b_proj2\n",
    "\n",
    "    # Final residual\n",
    "    block10_manual = x_resid1 + mlp_out\n",
    "\n",
    "# === STEP: Comparison ===\n",
    "diff = (block10_manual - gpt2_block10_output[\"block10\"]).abs()\n",
    "print(\"Block 10 Comparison Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Max difference: {diff.max().item()}\")\n",
    "print(f\"Mean difference: {diff.mean().item()}\")\n",
    "print(f\"Allclose (atol=1e-5)? {torch.allclose(block10_manual, gpt2_block10_output['block10'], atol=1e-5)}\")\n",
    "print(f\"Allclose (atol=1e-4)? {torch.allclose(block10_manual, gpt2_block10_output['block10'], atol=1e-4)}\")\n",
    "\n",
    "print(f\"\\nShape check:\")\n",
    "print(f\"Manual output shape: {block10_manual.shape}\")\n",
    "print(f\"GPT-2 output shape: {gpt2_block10_output['block10'].shape}\")\n",
    "\n",
    "print(f\"\\nFirst 5 values of manual output:\")\n",
    "print(block10_manual[0, :5])\n",
    "print(f\"\\nFirst 5 values of GPT-2 output:\")\n",
    "print(gpt2_block10_output['block10'][0, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6dc82395-64e3-4319-9036-e032f0e21be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 11 Comparison Results:\n",
      "==================================================\n",
      "Max difference: 0.00048828125\n",
      "Mean difference: 7.397434274025727e-06\n",
      "Allclose (atol=1e-5)? False\n",
      "Allclose (atol=1e-4)? True\n",
      "\n",
      "Shape check:\n",
      "Manual output shape: torch.Size([7, 768])\n",
      "GPT-2 output shape: torch.Size([7, 768])\n",
      "\n",
      "First 5 values of manual output:\n",
      "tensor([ 1.1101,  0.3077, -0.6339,  0.5480,  1.2614])\n",
      "\n",
      "First 5 values of GPT-2 output:\n",
      "tensor([ 1.1101,  0.3077, -0.6339,  0.5480,  1.2614])\n"
     ]
    }
   ],
   "source": [
    "# === STEP: Hook to capture GPT-2's actual block 11 output ===\n",
    "gpt2_block11_output = {}\n",
    "\n",
    "def block11_hook(module, input, output):\n",
    "    if isinstance(output, tuple):\n",
    "        gpt2_block11_output[\"block11\"] = output[0].detach().squeeze(0)\n",
    "    else:\n",
    "        gpt2_block11_output[\"block11\"] = output.detach().squeeze(0)\n",
    "\n",
    "hook_handle = model.h[11].register_forward_hook(block11_hook)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model(**inputs)\n",
    "\n",
    "hook_handle.remove()\n",
    "\n",
    "# === STEP: Manual calculation of block 11 ===\n",
    "with torch.no_grad():\n",
    "    # LayerNorm 1\n",
    "    ln1_weight = model.h[11].ln_1.weight.detach()\n",
    "    ln1_bias = model.h[11].ln_1.bias.detach()\n",
    "    x_norm = layer_norm(block10_manual, ln1_weight, ln1_bias)\n",
    "\n",
    "    # QKV\n",
    "    W_full = model.h[11].attn.c_attn.weight.detach()\n",
    "    b_full = model.h[11].attn.c_attn.bias.detach()\n",
    "    qkv = x_norm @ W_full + b_full\n",
    "    Q, K, V = qkv.split(768, dim=-1)\n",
    "\n",
    "    # Multi-head attention\n",
    "    Q_heads = split_heads(Q)\n",
    "    K_heads = split_heads(K)\n",
    "    V_heads = split_heads(V)\n",
    "\n",
    "    attn_outputs = []\n",
    "    for i in range(num_heads):\n",
    "        q, k, v = Q_heads[i], K_heads[i], V_heads[i]\n",
    "        scores = q @ k.T / (head_dim ** 0.5)\n",
    "        scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = weights @ v\n",
    "        attn_outputs.append(attn_output)\n",
    "\n",
    "    attn_concat = torch.cat(attn_outputs, dim=-1)\n",
    "\n",
    "    # Output projection - manual\n",
    "    W_proj = model.h[11].attn.c_proj.weight.detach()\n",
    "    b_proj = model.h[11].attn.c_proj.bias.detach()\n",
    "    manual_mixed = attn_concat @ W_proj + b_proj\n",
    "\n",
    "    # Residual\n",
    "    x_resid1 = block10_manual + manual_mixed\n",
    "\n",
    "    # LayerNorm 2\n",
    "    ln2_weight = model.h[11].ln_2.weight.detach()\n",
    "    ln2_bias = model.h[11].ln_2.bias.detach()\n",
    "    x_norm2 = layer_norm(x_resid1, ln2_weight, ln2_bias)\n",
    "\n",
    "    # MLP - manual\n",
    "    W_fc = model.h[11].mlp.c_fc.weight.detach()\n",
    "    b_fc = model.h[11].mlp.c_fc.bias.detach()\n",
    "    W_proj2 = model.h[11].mlp.c_proj.weight.detach()\n",
    "    b_proj2 = model.h[11].mlp.c_proj.bias.detach()\n",
    "\n",
    "    mlp_hidden = x_norm2 @ W_fc + b_fc\n",
    "    mlp_hidden = gelu(mlp_hidden)\n",
    "    mlp_out = mlp_hidden @ W_proj2 + b_proj2\n",
    "\n",
    "    # Final residual\n",
    "    block11_manual = x_resid1 + mlp_out\n",
    "\n",
    "# === STEP: Comparison ===\n",
    "diff = (block11_manual - gpt2_block11_output[\"block11\"]).abs()\n",
    "print(\"Block 11 Comparison Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Max difference: {diff.max().item()}\")\n",
    "print(f\"Mean difference: {diff.mean().item()}\")\n",
    "print(f\"Allclose (atol=1e-5)? {torch.allclose(block11_manual, gpt2_block11_output['block11'], atol=1e-5)}\")\n",
    "print(f\"Allclose (atol=1e-4)? {torch.allclose(block11_manual, gpt2_block11_output['block11'], atol=1e-4)}\")\n",
    "\n",
    "print(f\"\\nShape check:\")\n",
    "print(f\"Manual output shape: {block11_manual.shape}\")\n",
    "print(f\"GPT-2 output shape: {gpt2_block11_output['block11'].shape}\")\n",
    "\n",
    "print(f\"\\nFirst 5 values of manual output:\")\n",
    "print(block11_manual[0, :5])\n",
    "print(f\"\\nFirst 5 values of GPT-2 output:\")\n",
    "print(gpt2_block11_output['block11'][0, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "deadde29-fe71-4d20-813c-8fb29d419379",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final layer norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f8d0869-d991-4060-a633-a3a34d6e9d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final LayerNorm (ln_f) Comparison Results:\n",
      "==================================================\n",
      "Max difference: 0.0002899169921875\n",
      "Mean difference: 1.122443222811853e-06\n",
      "Allclose (atol=1e-5)? False\n",
      "Allclose (atol=1e-4)? True\n",
      "\n",
      "Shape check:\n",
      "Manual output shape: torch.Size([7, 768])\n",
      "GPT-2 output shape: torch.Size([7, 768])\n",
      "\n",
      "First 5 values of manual output:\n",
      "tensor([ 0.0603,  0.0134, -0.2300,  0.0012,  0.0006])\n",
      "\n",
      "First 5 values of GPT-2 output:\n",
      "tensor([ 0.0603,  0.0134, -0.2300,  0.0012,  0.0006])\n"
     ]
    }
   ],
   "source": [
    "# === STEP: Hook to capture GPT-2's final ln_f output ===\n",
    "gpt2_ln_f_output = {}\n",
    "\n",
    "def ln_f_hook(module, input, output):\n",
    "    gpt2_ln_f_output[\"ln_f\"] = output.detach().squeeze(0)\n",
    "\n",
    "hook_handle = model.ln_f.register_forward_hook(ln_f_hook)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model(**inputs)\n",
    "\n",
    "hook_handle.remove()\n",
    "\n",
    "# === STEP: Manual calculation of ln_f ===\n",
    "ln_f_weight = model.ln_f.weight.detach()\n",
    "ln_f_bias = model.ln_f.bias.detach()\n",
    "\n",
    "with torch.no_grad():\n",
    "    final_output_manual = layer_norm(block11_manual, ln_f_weight, ln_f_bias)\n",
    "\n",
    "# === STEP: Comparison ===\n",
    "diff = (final_output_manual - gpt2_ln_f_output[\"ln_f\"]).abs()\n",
    "print(\"Final LayerNorm (ln_f) Comparison Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Max difference: {diff.max().item()}\")\n",
    "print(f\"Mean difference: {diff.mean().item()}\")\n",
    "print(f\"Allclose (atol=1e-5)? {torch.allclose(final_output_manual, gpt2_ln_f_output['ln_f'], atol=1e-5)}\")\n",
    "print(f\"Allclose (atol=1e-4)? {torch.allclose(final_output_manual, gpt2_ln_f_output['ln_f'], atol=1e-4)}\")\n",
    "\n",
    "print(f\"\\nShape check:\")\n",
    "print(f\"Manual output shape: {final_output_manual.shape}\")\n",
    "print(f\"GPT-2 output shape: {gpt2_ln_f_output['ln_f'].shape}\")\n",
    "\n",
    "print(f\"\\nFirst 5 values of manual output:\")\n",
    "print(final_output_manual[0, :5])\n",
    "print(f\"\\nFirst 5 values of GPT-2 output:\")\n",
    "print(gpt2_ln_f_output['ln_f'][0, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9da021b6-8740-4e9f-ab4c-0eb49cd5ace0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Decoded Text:\n",
      ".source codeVM are.\n",
      "\n",
      "\n",
      "GPT-2 Decoded Text:\n",
      ".source codeVM are.\n",
      "\n",
      "\n",
      "--- Token Match ---\n",
      "Token IDs match? True\n",
      "Text match? True\n"
     ]
    }
   ],
   "source": [
    "# === STEP 1: Manually project final hidden states to logits ===\n",
    "# GPT-2 uses a tied weight matrix: lm_head is just a linear projection\n",
    "# that shares weights with the token embedding layer (wte)\n",
    "\n",
    "# Get the token embedding matrix (vocab_size x hidden_dim)\n",
    "lm_head_weight = model.wte.weight.detach()  # shape: [50257, 768]\n",
    "\n",
    "# Multiply final output (seq_len x hidden_dim) with transpose of lm_head weights\n",
    "# This gives logits of shape (seq_len x vocab_size)\n",
    "with torch.no_grad():\n",
    "    logits_manual = final_output_manual @ lm_head_weight.T  # [seq_len, vocab_size]\n",
    "\n",
    "# === STEP 2: Compare against GPT-2's own logits ===\n",
    "# GPT-2 does not expose logits directly unless using GPT2LMHeadModel\n",
    "# So we manually reconstruct them here using:\n",
    "# logits = last_hidden_state @ lm_head_weight.T\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get hidden states from GPT-2\n",
    "    hidden_states = model(**inputs).last_hidden_state.squeeze(0)  # [seq_len, hidden_dim]\n",
    "\n",
    "    # Use same projection as manual path\n",
    "    gpt2_logits = hidden_states @ lm_head_weight.T  # [seq_len, vocab_size]\n",
    "\n",
    "# === STEP 3: Decode predicted tokens from manual logits ===\n",
    "# We take the argmax over vocabulary at each position to find most likely token\n",
    "predicted_ids_manual = torch.argmax(logits_manual, dim=-1)  # [seq_len]\n",
    "\n",
    "# === STEP 4: Decode predicted tokens from GPT-2 logits for comparison ===\n",
    "predicted_ids_gpt2 = torch.argmax(gpt2_logits, dim=-1)  # [seq_len]\n",
    "\n",
    "# === STEP 5: Decode token IDs into strings ===\n",
    "# This reconstructs the textual output GPT-2 would generate\n",
    "decoded_manual = tokenizer.decode(predicted_ids_manual)\n",
    "decoded_gpt2 = tokenizer.decode(predicted_ids_gpt2)\n",
    "\n",
    "# === STEP 6: Compare results ===\n",
    "print(\"Manual Decoded Text:\")\n",
    "print(decoded_manual)\n",
    "\n",
    "print(\"\\nGPT-2 Decoded Text:\")\n",
    "print(decoded_gpt2)\n",
    "\n",
    "print(\"\\n--- Token Match ---\")\n",
    "print(\"Token IDs match?\", torch.equal(predicted_ids_manual, predicted_ids_gpt2))\n",
    "print(\"Text match?\", decoded_manual == decoded_gpt2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
